{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import random as rd\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Common Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import copy as cp\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, average_precision_score\n",
    "from collections import defaultdict\n",
    "\n",
    "# load the data, including relations, adj, features and labels.\n",
    "def load_data(data):\n",
    "\n",
    "    data_file = loadmat('data/YelpChi.mat')\n",
    "    labels = data_file['label'].flatten()\n",
    "    feat_data = data_file['features'].todense().A\n",
    "    # load the preprocessed adj\n",
    "    with open('data/yelp_rur_adjlists.pickle', 'rb') as file:\n",
    "        relation1 = pickle.load(file)\n",
    "    file.close()\n",
    "    with open('data/yelp_rtr_adjlists.pickle', 'rb') as file:\n",
    "        relation2 = pickle.load(file)\n",
    "    file.close()\n",
    "    with open('data/yelp_rsr_adjlists.pickle', 'rb') as file:\n",
    "        relation3 = pickle.load(file)\n",
    "    file.close()\n",
    "    with open('data/yelp_homo_adjlists.pickle', 'rb') as file:\n",
    "        homo = pickle.load(file)\n",
    "    file.close()\n",
    "        \n",
    "    return [homo, relation1, relation2, relation3], feat_data, labels\n",
    "\n",
    "# normalize the features\n",
    "def normalize(mx):\n",
    "    rowsum = np.array(mx.sum(1)) + 0.01\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "# split to the possitive and negative items\n",
    "def pos_neg_split(nodes, labels):\n",
    "    pos_nodes = []\n",
    "    neg_nodes = cp.deepcopy(nodes)\n",
    "    aux_nodes = cp.deepcopy(nodes)\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label == 1:\n",
    "            pos_nodes.append(aux_nodes[idx])\n",
    "            neg_nodes.remove(aux_nodes[idx])\n",
    "\n",
    "    return pos_nodes, neg_nodes\n",
    "\n",
    "# slove the problem of undersample\n",
    "def undersample(pos_nodes, neg_nodes, scale=1):  \n",
    "    aux_nodes = cp.deepcopy(neg_nodes)\n",
    "    num_need = int(len(pos_nodes)*scale)\n",
    "    aux_nodes = rd.sample(aux_nodes, k = num_need)\n",
    "    batch_nodes = pos_nodes + aux_nodes\n",
    "    return batch_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Set Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run on yelp\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "parser = argparse.ArgumentParser()\n",
    "epoch_set = 31\n",
    "\n",
    "# dataset and model dependent args\n",
    "parser.add_argument('--data', type=str, default='yelp', help='yelp data')\n",
    "parser.add_argument('--model', type=str, default='CARE', help='CARE model')\n",
    "parser.add_argument('--inter', type=str, default='GNN', help='The aggregator type. [Att, Weight, Mean, GNN]')\n",
    "parser.add_argument('--batch-size', type=int, default=1024, help='1024 for yelp')\n",
    "\n",
    "# hyper-parameters\n",
    "parser.add_argument('--lr', type=float, default=0.01, help='learning rate.')\n",
    "parser.add_argument('--lambda_1', type=float, default=2, help='Simi loss weight.')\n",
    "parser.add_argument('--lambda_2', type=float, default=1e-3, help='Weight decay (L2 loss weight).')\n",
    "parser.add_argument('--emb-size', type=int, default=64, help='Node embedding size at the last layer.')\n",
    "parser.add_argument('--num-epochs', type=int, default=epoch_set, help='Number of epochs.')\n",
    "parser.add_argument('--test-epochs', type=int, default=3, help='Test while reach the epoch number required')\n",
    "parser.add_argument('--under-sample', type=int, default=1, help='Under-sampling scale.')\n",
    "parser.add_argument('--step-size', type=float, default=2e-2, help='RL action step size')\n",
    "\n",
    "# other args\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False, help='Disables CUDA training.')\n",
    "parser.add_argument('--seed', type=int, default=72, help='Random seed.')\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "args, unknown = parser.parse_known_args() # in jupter \n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "print(f'run on {args.data}')\n",
    "\n",
    "# load graph, feature, and label\n",
    "[homo, relation1, relation2, relation3], feat_data, labels = load_data(args.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three - Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nR-U-R: it connects reviews posted by the same user\\nR-T-R: it connects two reviews under the same product posted in the same month.\\nR-S-R: it connects reviews under the same product with the same star rating (1-5 stars)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "R-U-R: it connects reviews posted by the same user\n",
    "R-T-R: it connects two reviews under the same product posted in the same month.\n",
    "R-S-R: it connects reviews under the same product with the same star rating (1-5 stars)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10, 11}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-U-R\n",
    "relation1[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10, 14, 20, 40}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-T-R\n",
    "relation2[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8, 10, 16, 17, 50, 54, 61, 6695, 6697}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R-S-R\n",
    "relation3[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features (45954, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02237555, 0.07049484, 0.42868165, ..., 0.5920398 , 0.13930348,\n",
       "        0.49751244],\n",
       "       [0.02492767, 0.99998516, 0.99998516, ..., 0.5920398 , 0.13930348,\n",
       "        0.49751244],\n",
       "       [0.00617256, 0.07049484, 0.42868165, ..., 0.5920398 , 0.13930348,\n",
       "        0.49751244],\n",
       "       ...,\n",
       "       [0.00908079, 0.35002597, 0.42868165, ..., 0.48258706, 0.80099502,\n",
       "        0.1641791 ],\n",
       "       [0.00617256, 0.07049484, 0.99998516, ..., 0.44278607, 0.44776119,\n",
       "        0.58706468],\n",
       "       [0.00317531, 0.35002597, 0.42868165, ..., 0.44278607, 0.44776119,\n",
       "        0.58706468]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"shape of features\",feat_data.shape)\n",
    "feat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_data_df = pd.DataFrame(feat_data,columns = [\"x\"+str(i) for i in range(1,33)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "      <td>45954.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.487706</td>\n",
       "      <td>0.497164</td>\n",
       "      <td>0.757261</td>\n",
       "      <td>0.956293</td>\n",
       "      <td>0.977870</td>\n",
       "      <td>0.751894</td>\n",
       "      <td>0.513187</td>\n",
       "      <td>0.500954</td>\n",
       "      <td>0.503624</td>\n",
       "      <td>0.592509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949713</td>\n",
       "      <td>0.505795</td>\n",
       "      <td>0.777519</td>\n",
       "      <td>0.525344</td>\n",
       "      <td>0.509241</td>\n",
       "      <td>0.515480</td>\n",
       "      <td>0.527980</td>\n",
       "      <td>0.464007</td>\n",
       "      <td>0.442475</td>\n",
       "      <td>0.506883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.290197</td>\n",
       "      <td>0.289086</td>\n",
       "      <td>0.282411</td>\n",
       "      <td>0.199618</td>\n",
       "      <td>0.145335</td>\n",
       "      <td>0.296119</td>\n",
       "      <td>0.303626</td>\n",
       "      <td>0.289249</td>\n",
       "      <td>0.288164</td>\n",
       "      <td>0.362085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.286477</td>\n",
       "      <td>0.244749</td>\n",
       "      <td>0.323564</td>\n",
       "      <td>0.353809</td>\n",
       "      <td>0.326228</td>\n",
       "      <td>0.315453</td>\n",
       "      <td>0.323116</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.296722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.428682</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.022791</td>\n",
       "      <td>0.398457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.098019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948060</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034826</td>\n",
       "      <td>0.139303</td>\n",
       "      <td>0.009950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.232183</td>\n",
       "      <td>0.235789</td>\n",
       "      <td>0.428682</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.398457</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.250627</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.280318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948060</td>\n",
       "      <td>0.258020</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.144279</td>\n",
       "      <td>0.189055</td>\n",
       "      <td>0.228856</td>\n",
       "      <td>0.228856</td>\n",
       "      <td>0.139303</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.228856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.483908</td>\n",
       "      <td>0.505364</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.510364</td>\n",
       "      <td>0.500490</td>\n",
       "      <td>0.504696</td>\n",
       "      <td>0.510216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948060</td>\n",
       "      <td>0.508394</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.592040</td>\n",
       "      <td>0.467662</td>\n",
       "      <td>0.517413</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.383085</td>\n",
       "      <td>0.547264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.737903</td>\n",
       "      <td>0.738037</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.752281</td>\n",
       "      <td>0.751821</td>\n",
       "      <td>0.754166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948060</td>\n",
       "      <td>0.753251</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.860697</td>\n",
       "      <td>0.855721</td>\n",
       "      <td>0.815920</td>\n",
       "      <td>0.781095</td>\n",
       "      <td>0.716418</td>\n",
       "      <td>0.736318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>0.995025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x1            x2            x3            x4            x5  \\\n",
       "count  45954.000000  45954.000000  45954.000000  45954.000000  45954.000000   \n",
       "mean       0.487706      0.497164      0.757261      0.956293      0.977870   \n",
       "std        0.290197      0.289086      0.282411      0.199618      0.145335   \n",
       "min        0.003175      0.000237      0.428682      0.044321      0.022791   \n",
       "25%        0.232183      0.235789      0.428682      0.999985      0.999985   \n",
       "50%        0.483908      0.505364      0.999985      0.999985      0.999985   \n",
       "75%        0.737903      0.738037      0.999985      0.999985      0.999985   \n",
       "max        1.000000      0.999985      0.999985      0.999985      0.999985   \n",
       "\n",
       "                 x6            x7            x8            x9           x10  \\\n",
       "count  45954.000000  45954.000000  45954.000000  45954.000000  45954.000000   \n",
       "mean       0.751894      0.513187      0.500954      0.503624      0.592509   \n",
       "std        0.296119      0.303626      0.289249      0.288164      0.362085   \n",
       "min        0.398457      0.000000      0.000045      0.000015      0.098019   \n",
       "25%        0.398457      0.252600      0.250627      0.257200      0.280318   \n",
       "50%        0.999985      0.510364      0.500490      0.504696      0.510216   \n",
       "75%        0.999985      0.752281      0.751821      0.754166      1.000000   \n",
       "max        0.999985      0.999985      0.999985      1.000000      1.000000   \n",
       "\n",
       "       ...           x23           x24           x25           x26  \\\n",
       "count  ...  45954.000000  45954.000000  45954.000000  45954.000000   \n",
       "mean   ...      0.949713      0.505795      0.777519      0.525344   \n",
       "std    ...      0.007634      0.286477      0.244749      0.323564   \n",
       "min    ...      0.948060      0.000026      0.004975      0.089552   \n",
       "25%    ...      0.948060      0.258020      0.736318      0.144279   \n",
       "50%    ...      0.948060      0.508394      0.736318      0.592040   \n",
       "75%    ...      0.948060      0.753251      0.995025      0.825871   \n",
       "max    ...      1.000000      0.999947      0.995025      0.995025   \n",
       "\n",
       "                x27           x28           x29           x30           x31  \\\n",
       "count  45954.000000  45954.000000  45954.000000  45954.000000  45954.000000   \n",
       "mean       0.509241      0.515480      0.527980      0.464007      0.442475   \n",
       "std        0.353809      0.326228      0.315453      0.323116      0.278126   \n",
       "min        0.000000      0.000000      0.000000      0.034826      0.139303   \n",
       "25%        0.189055      0.228856      0.228856      0.139303      0.149254   \n",
       "50%        0.467662      0.517413      0.552239      0.462687      0.383085   \n",
       "75%        0.860697      0.855721      0.815920      0.781095      0.716418   \n",
       "max        0.995025      0.995025      0.995025      1.000000      1.000000   \n",
       "\n",
       "                x32  \n",
       "count  45954.000000  \n",
       "mean       0.506883  \n",
       "std        0.296722  \n",
       "min        0.009950  \n",
       "25%        0.228856  \n",
       "50%        0.547264  \n",
       "75%        0.736318  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_total: 45954\n",
      "n_pos: 6677 \t n_neg: 39277\n"
     ]
    }
   ],
   "source": [
    "# pos and neg counts\n",
    "print(\"n_total:\",len(labels))\n",
    "print(\"n_pos:\",np.sum(labels),\"\\t\",\"n_neg:\",len(labels)-np.sum(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model and CARE-GNN Layers (Refer the Paper and Github Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from operator import itemgetter\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "CARE-GNN Layers\n",
    "Paper: Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters\n",
    "Source: https://github.com/YingtongDou/CARE-GNN\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class InterAgg(nn.Module):\n",
    "\n",
    "    def __init__(self, features, feature_dim,\n",
    "                 embed_dim, adj_lists, intraggs,\n",
    "                 inter='GNN', step_size=0.02, cuda=True):\n",
    "        \n",
    "        super(InterAgg, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "        self.dropout = 0.6\n",
    "        self.adj_lists = adj_lists\n",
    "        self.intra_agg1 = intraggs[0]\n",
    "        self.intra_agg2 = intraggs[1]\n",
    "        self.intra_agg3 = intraggs[2]\n",
    "        self.embed_dim = embed_dim\n",
    "        self.feat_dim = feature_dim\n",
    "        self.inter = inter\n",
    "        self.step_size = step_size\n",
    "        self.cuda = cuda\n",
    "        self.intra_agg1.cuda = cuda\n",
    "        self.intra_agg2.cuda = cuda\n",
    "        self.intra_agg3.cuda = cuda\n",
    "\n",
    "        # set RL\n",
    "        self.RL = True\n",
    "\n",
    "        # initial batch num \n",
    "        self.batch_num = 0\n",
    "\n",
    "        # initial filtering thresholds\n",
    "        self.thresholds = [0.5, 0.5, 0.5]\n",
    "\n",
    "        # the activation function used by attention mechanism\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "        # parameter used to transform node embeddings before inter-relation aggregation\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(self.embed_dim, self.feat_dim))\n",
    "        init.xavier_uniform_(self.weight)\n",
    "\n",
    "        # weight parameter for each relation used by CARE-Weight\n",
    "        self.alpha = nn.Parameter(torch.FloatTensor(self.embed_dim, 3))\n",
    "        init.xavier_uniform_(self.alpha)\n",
    "\n",
    "        # parameters used by attention layer\n",
    "        self.a = nn.Parameter(torch.FloatTensor(2 * self.embed_dim, 1))\n",
    "        init.xavier_uniform_(self.a)\n",
    "\n",
    "        # label predictor for similarity measure\n",
    "        self.label_clf = nn.Linear(self.feat_dim, 2)\n",
    "\n",
    "        # initialize the parameter logs\n",
    "        self.weights_log = []\n",
    "        self.thresholds_log = [self.thresholds]\n",
    "        self.relation_score_log = []\n",
    "\n",
    "    def forward(self, nodes, labels, train_flag=True):\n",
    "        # extract 1-hop neighbor ids from adj lists of each single-relation graph\n",
    "        to_neighs = []\n",
    "        for adj_list in self.adj_lists:\n",
    "            to_neighs.append([set(adj_list[int(node)]) for node in nodes])\n",
    "\n",
    "        # find unique nodes and their neighbors used in current batch\n",
    "        unique_nodes = set.union(set.union(*to_neighs[0]), set.union(*to_neighs[1]),\n",
    "                                 set.union(*to_neighs[2], set(nodes)))\n",
    "\n",
    "        # calculate label-aware scores\n",
    "        if self.cuda:\n",
    "            batch_features = self.features(torch.cuda.LongTensor(list(unique_nodes)))\n",
    "        else:\n",
    "            batch_features = self.features(torch.LongTensor(list(unique_nodes)))\n",
    "        batch_scores = self.label_clf(batch_features)\n",
    "        id_mapping = {node_id: index for node_id, index in zip(unique_nodes, range(len(unique_nodes)))}\n",
    "\n",
    "        # the label-aware scores for current batch of nodes\n",
    "        center_scores = batch_scores[itemgetter(*nodes)(id_mapping), :]\n",
    "\n",
    "        # get neighbor node id list for each batch node and relation\n",
    "        r1_list = [list(to_neigh) for to_neigh in to_neighs[0]]\n",
    "        r2_list = [list(to_neigh) for to_neigh in to_neighs[1]]\n",
    "        r3_list = [list(to_neigh) for to_neigh in to_neighs[2]]\n",
    "\n",
    "        # assign label-aware scores to neighbor nodes for each batch node and relation\n",
    "        r1_scores = [batch_scores[itemgetter(*to_neigh)(id_mapping), :].view(-1, 2) for to_neigh in r1_list]\n",
    "        r2_scores = [batch_scores[itemgetter(*to_neigh)(id_mapping), :].view(-1, 2) for to_neigh in r2_list]\n",
    "        r3_scores = [batch_scores[itemgetter(*to_neigh)(id_mapping), :].view(-1, 2) for to_neigh in r3_list]\n",
    "\n",
    "        # count the number of neighbors kept for aggregation for each batch node and relation\n",
    "        r1_sample_num_list = [math.ceil(len(neighs) * self.thresholds[0]) for neighs in r1_list]\n",
    "        r2_sample_num_list = [math.ceil(len(neighs) * self.thresholds[1]) for neighs in r2_list]\n",
    "        r3_sample_num_list = [math.ceil(len(neighs) * self.thresholds[2]) for neighs in r3_list]\n",
    "\n",
    "        # intra-aggregation steps for each relation\n",
    "        r1_feats, r1_scores = self.intra_agg1.forward(nodes, r1_list, center_scores, r1_scores, r1_sample_num_list)\n",
    "        r2_feats, r2_scores = self.intra_agg2.forward(nodes, r2_list, center_scores, r2_scores, r2_sample_num_list)\n",
    "        r3_feats, r3_scores = self.intra_agg3.forward(nodes, r3_list, center_scores, r3_scores, r3_sample_num_list)\n",
    "\n",
    "        # concat the intra-aggregated embeddings from each relation\n",
    "        neigh_feats = torch.cat((r1_feats, r2_feats, r3_feats), dim=0)\n",
    "\n",
    "        # get features or embeddings for batch nodes\n",
    "        if self.cuda and isinstance(nodes, list):\n",
    "            index = torch.LongTensor(nodes).cuda()\n",
    "        else:\n",
    "            index = torch.LongTensor(nodes)\n",
    "        self_feats = self.features(index)\n",
    "\n",
    "        # number of nodes in a batch\n",
    "        n = len(nodes)\n",
    "\n",
    "        # inter-relation aggregation steps\n",
    "        if self.inter == 'GNN':\n",
    "            # 4) CARE-GNN Inter-relation Aggregator\n",
    "            combined = threshold_inter_agg(len(self.adj_lists), self_feats, neigh_feats, self.embed_dim, self.weight, self.thresholds, n, self.cuda)\n",
    "\n",
    "        # the reinforcement learning module\n",
    "        if self.RL and train_flag:\n",
    "            relation_scores, rewards, thresholds, stop_flag = RLModule([r1_scores, r2_scores, r3_scores],\n",
    "                                                                       self.relation_score_log, labels, self.thresholds,\n",
    "                                                                       self.batch_num, self.step_size)\n",
    "            self.thresholds = thresholds\n",
    "            self.RL = stop_flag\n",
    "            self.relation_score_log.append(relation_scores)\n",
    "            self.thresholds_log.append(self.thresholds)\n",
    "\n",
    "        return combined, center_scores\n",
    "\n",
    "\n",
    "class IntraAgg(nn.Module):\n",
    "\n",
    "    def __init__(self, features, feat_dim, cuda=False):\n",
    "        \n",
    "        super(IntraAgg, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "        self.cuda = cuda\n",
    "        self.feat_dim = feat_dim\n",
    "\n",
    "    def forward(self, nodes, to_neighs_list, batch_scores, neigh_scores, sample_list):\n",
    "\n",
    "        # filer neighbors under given relation\n",
    "        samp_neighs, samp_scores = filter_neighs_ada_threshold(batch_scores, neigh_scores, to_neighs_list, sample_list)\n",
    "\n",
    "        # find the unique nodes among batch nodes and the filtered neighbors\n",
    "        unique_nodes_list = list(set.union(*samp_neighs))\n",
    "        unique_nodes = {n: i for i, n in enumerate(unique_nodes_list)}\n",
    "\n",
    "        # intra-relation aggregation only with sampled neighbors\n",
    "        mask = Variable(torch.zeros(len(samp_neighs), len(unique_nodes)))\n",
    "        column_indices = [unique_nodes[n] for samp_neigh in samp_neighs for n in samp_neigh]\n",
    "        row_indices = [i for i in range(len(samp_neighs)) for _ in range(len(samp_neighs[i]))]\n",
    "        mask[row_indices, column_indices] = 1\n",
    "        if self.cuda:\n",
    "            mask = mask.cuda()\n",
    "        num_neigh = mask.sum(1, keepdim=True)\n",
    "        mask = mask.div(num_neigh)\n",
    "        if self.cuda:\n",
    "            embed_matrix = self.features(torch.LongTensor(unique_nodes_list).cuda())\n",
    "        else:\n",
    "            embed_matrix = self.features(torch.LongTensor(unique_nodes_list))\n",
    "        to_feats = mask.mm(embed_matrix)\n",
    "        to_feats = F.relu(to_feats)\n",
    "        return to_feats, samp_scores\n",
    "\n",
    "\n",
    "def RLModule(scores, scores_log, labels, thresholds, batch_num, step_size):\n",
    "\n",
    "    relation_scores = []\n",
    "    stop_flag = True\n",
    "\n",
    "    # only compute the average neighbor distances for positive nodes\n",
    "    pos_index = (labels == 1).nonzero().tolist()\n",
    "    pos_index = [i[0] for i in pos_index]\n",
    "\n",
    "    # compute average neighbor distances for each relation\n",
    "    for score in scores:\n",
    "        pos_scores = itemgetter(*pos_index)(score)\n",
    "        neigh_count = sum([1 if isinstance(i, float) else len(i) for i in pos_scores])\n",
    "        pos_sum = [i if isinstance(i, float) else sum(i) for i in pos_scores]\n",
    "        relation_scores.append(sum(pos_sum) / neigh_count)\n",
    "\n",
    "    if len(scores_log) % batch_num != 0 or len(scores_log) < 2 * batch_num:\n",
    "        # do not call RL module within the epoch or within the first two epochs\n",
    "        rewards = [0, 0, 0]\n",
    "        new_thresholds = thresholds\n",
    "    else:\n",
    "        # update thresholds according to average scores in last epoch\n",
    "        # Eq.(5) in the paper\n",
    "        previous_epoch_scores = [sum(s) / batch_num for s in zip(*scores_log[-2 * batch_num:-batch_num])]\n",
    "        current_epoch_scores = [sum(s) / batch_num for s in zip(*scores_log[-batch_num:])]\n",
    "\n",
    "        # compute reward for each relation and update the thresholds according to reward\n",
    "        # Eq. (6) in the paper\n",
    "        rewards = [1 if previous_epoch_scores[i] - s >= 0 else -1 for i, s in enumerate(current_epoch_scores)]\n",
    "        new_thresholds = [thresholds[i] + step_size if r == 1 else thresholds[i] - step_size for i, r in enumerate(rewards)]\n",
    "\n",
    "        # avoid overflow\n",
    "        new_thresholds = [0.999 if i > 1 else i for i in new_thresholds]\n",
    "        new_thresholds = [0.001 if i < 0 else i for i in new_thresholds]\n",
    "\n",
    "        print(f'epoch scores: {current_epoch_scores}')\n",
    "        print(f'rewards: {rewards}')\n",
    "        print(f'thresholds: {new_thresholds}')\n",
    "\n",
    "    # TODO: add terminal condition\n",
    "\n",
    "    return relation_scores, rewards, new_thresholds, stop_flag\n",
    "\n",
    "\n",
    "def filter_neighs_ada_threshold(center_scores, neigh_scores, neighs_list, sample_list):\n",
    "\n",
    "    samp_neighs = []\n",
    "    samp_scores = []\n",
    "    for idx, center_score in enumerate(center_scores):\n",
    "        center_score = center_scores[idx][0]\n",
    "        neigh_score = neigh_scores[idx][:, 0].view(-1, 1)\n",
    "        center_score = center_score.repeat(neigh_score.size()[0], 1)\n",
    "        neighs_indices = neighs_list[idx]\n",
    "        num_sample = sample_list[idx]\n",
    "\n",
    "        # compute the L1-distance of batch nodes and their neighbors\n",
    "        score_diff = torch.abs(center_score - neigh_score).squeeze()\n",
    "        sorted_scores, sorted_indices = torch.sort(score_diff, dim=0, descending=False)\n",
    "        selected_indices = sorted_indices.tolist()\n",
    "\n",
    "        # top-p sampling according to distance ranking and thresholds\n",
    "        if len(neigh_scores[idx]) > num_sample + 1:\n",
    "            selected_neighs = [neighs_indices[n] for n in selected_indices[:num_sample]]\n",
    "            selected_scores = sorted_scores.tolist()[:num_sample]\n",
    "        else:\n",
    "            selected_neighs = neighs_indices\n",
    "            selected_scores = score_diff.tolist()\n",
    "            if isinstance(selected_scores, float):\n",
    "                selected_scores = [selected_scores]\n",
    "\n",
    "        samp_neighs.append(set(selected_neighs))\n",
    "        samp_scores.append(selected_scores)\n",
    "\n",
    "    return samp_neighs, samp_scores\n",
    "\n",
    "def threshold_inter_agg(num_relations, self_feats, neigh_feats, embed_dim, weight, threshold, n, cuda):\n",
    "\n",
    "    # transform batch node embedding and neighbor embedding in each relation with weight parameter\n",
    "    center_h = weight.mm(self_feats.t())\n",
    "    neigh_h = weight.mm(neigh_feats.t())\n",
    "\n",
    "    if cuda:\n",
    "        # use thresholds as aggregating weights\n",
    "        w = torch.FloatTensor(threshold).repeat(weight.size(0), 1).cuda()\n",
    "\n",
    "        # initialize the final neighbor embedding\n",
    "        aggregated = torch.zeros(size=(embed_dim, n)).cuda()\n",
    "    else:\n",
    "        w = torch.FloatTensor(threshold).repeat(weight.size(0), 1)\n",
    "        aggregated = torch.zeros(size=(embed_dim, n))\n",
    "\n",
    "    # add weighted neighbor embeddings in each relation together\n",
    "    for r in range(num_relations):\n",
    "        aggregated += torch.mul(w[:, r].unsqueeze(1).repeat(1, n), neigh_h[:, r * n:(r + 1) * n])\n",
    "\n",
    "    # sum aggregated neighbor embedding and batch node embedding\n",
    "    # feed them to activation function\n",
    "    combined = F.relu(center_h + aggregated)\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "class OneLayerCARE(nn.Module):\n",
    "    def __init__(self, num_classes, inter1, lambda_1):\n",
    "        super(OneLayerCARE, self).__init__()\n",
    "        self.inter1 = inter1\n",
    "        self.xent = nn.CrossEntropyLoss()\n",
    "\n",
    "        # the parameter to transform the final embedding\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, inter1.embed_dim))\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        self.lambda_1 = lambda_1\n",
    "\n",
    "    def forward(self, nodes, labels, train_flag=True):\n",
    "        embeds1, label_scores = self.inter1(nodes, labels, train_flag)\n",
    "        scores = self.weight.mm(embeds1)\n",
    "        return scores.t(), label_scores\n",
    "\n",
    "    def to_prob(self, nodes, labels, train_flag=True):\n",
    "        gnn_logits, label_logits = self.forward(nodes, labels, train_flag)\n",
    "        gnn_scores = torch.sigmoid(gnn_logits)\n",
    "        label_scores = torch.sigmoid(label_logits)\n",
    "        return gnn_scores, label_scores\n",
    "\n",
    "    def loss(self, nodes, labels, train_flag=True):\n",
    "        gnn_scores, label_scores = self.forward(nodes, labels, train_flag)\n",
    "        # Simi loss, Eq. (4) in the paper\n",
    "        label_loss = self.xent(label_scores, labels.squeeze())\n",
    "        # GNN loss, Eq. (10) in the paper\n",
    "        gnn_loss = self.xent(gnn_scores, labels.squeeze())\n",
    "        # the loss function of CARE-GNN, Eq. (11) in the paper\n",
    "        final_loss = gnn_loss + self.lambda_1 * label_loss\n",
    "        return final_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test split\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "index = list(range(len(labels)))\n",
    "idx_train, idx_test, y_train, y_test = train_test_split(index, labels, stratify=labels, test_size=0.60,\n",
    "                                                            random_state=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 18381\n",
      "test_data: 27573\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data:\",len(idx_train))\n",
    "print(\"test_data:\",len(idx_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CARE, Inter-AGG: GNN, emb_size: 64.\n"
     ]
    }
   ],
   "source": [
    "# split pos neg sets for under-sampling\n",
    "train_pos, train_neg = pos_neg_split(idx_train, y_train)\n",
    "\n",
    "# initialize model input\n",
    "features = nn.Embedding(feat_data.shape[0], feat_data.shape[1])\n",
    "feat_data = normalize(feat_data)\n",
    "features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
    "if args.cuda:\n",
    "    features.cuda()\n",
    "\n",
    "# set input graph\n",
    "adj_lists = [relation1, relation2, relation3]\n",
    "\n",
    "print(f'Model: {args.model}, Inter-AGG: {args.inter}, emb_size: {args.emb_size}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0012, 0.0037, 0.0224,  ..., 0.0310, 0.0073, 0.0260],\n",
       "        [0.0013, 0.0503, 0.0503,  ..., 0.0298, 0.0070, 0.0250],\n",
       "        [0.0003, 0.0040, 0.0240,  ..., 0.0332, 0.0078, 0.0279],\n",
       "        ...,\n",
       "        [0.0006, 0.0220, 0.0269,  ..., 0.0303, 0.0503, 0.0103],\n",
       "        [0.0003, 0.0037, 0.0520,  ..., 0.0230, 0.0233, 0.0305],\n",
       "        [0.0002, 0.0220, 0.0270,  ..., 0.0279, 0.0282, 0.0370]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build one-layer models\n",
    "intra1 = IntraAgg(features, feat_data.shape[1], cuda=args.cuda)\n",
    "intra2 = IntraAgg(features, feat_data.shape[1], cuda=args.cuda)\n",
    "intra3 = IntraAgg(features, feat_data.shape[1], cuda=args.cuda)\n",
    "inter1 = InterAgg(features, feat_data.shape[1], args.emb_size, adj_lists, [intra1, intra2, intra3], inter=args.inter,\n",
    "                  step_size=args.step_size, cuda=args.cuda)\n",
    "\n",
    "gnn_model = OneLayerCARE(2, inter1, args.lambda_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneLayerCARE(\n",
      "  (inter1): InterAgg(\n",
      "    (features): Embedding(45954, 32)\n",
      "    (intra_agg1): IntraAgg(\n",
      "      (features): Embedding(45954, 32)\n",
      "    )\n",
      "    (intra_agg2): IntraAgg(\n",
      "      (features): Embedding(45954, 32)\n",
      "    )\n",
      "    (intra_agg3): IntraAgg(\n",
      "      (features): Embedding(45954, 32)\n",
      "    )\n",
      "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
      "    (label_clf): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      "  (xent): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record info\n",
    "loss_dict = {}\n",
    "label_dict = {}\n",
    "count = 0\n",
    "label_dict[\"acc\"] = {}\n",
    "label_dict[\"auc\"] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test (I regard test as validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "def test_care(test_cases, labels, model, batch_size,label_dict,count):\n",
    "    \"\"\"\n",
    "    Test the performance of CARE-GNN and its variants\n",
    "    :param test_cases: a list of testing node\n",
    "    :param labels: a list of testing node labels\n",
    "    :param model: the GNN model\n",
    "    :param batch_size: number nodes in a batch\n",
    "    :returns: the AUC and Recall of GNN and Simi modules\n",
    "    \"\"\"\n",
    "\n",
    "    test_batch_num = int(len(test_cases) / batch_size) + 1\n",
    "    f1_gnn = 0.0\n",
    "    acc_gnn = 0.0\n",
    "    recall_gnn = 0.0\n",
    "    f1_label1 = 0.0\n",
    "    acc_label1 = 0.00\n",
    "    recall_label1 = 0.0\n",
    "    gnn_list = []\n",
    "    label_list1 = []\n",
    "    label_actual = []\n",
    "    label_prediction = []\n",
    "    label_index = []\n",
    "    for iteration in range(test_batch_num):\n",
    "        i_start = iteration * batch_size\n",
    "        i_end = min((iteration + 1) * batch_size, len(test_cases))\n",
    "        batch_nodes = test_cases[i_start:i_end]\n",
    "        batch_label = labels[i_start:i_end]\n",
    "        gnn_prob, label_prob1 = model.to_prob(batch_nodes, batch_label, train_flag=False)\n",
    "\n",
    "        f1_gnn += f1_score(batch_label, gnn_prob.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
    "        acc_gnn += accuracy_score(batch_label, gnn_prob.data.cpu().numpy().argmax(axis=1))\n",
    "        recall_gnn += recall_score(batch_label, gnn_prob.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
    "\n",
    "        f1_label1 += f1_score(batch_label, label_prob1.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
    "        acc_label1 += accuracy_score(batch_label, label_prob1.data.cpu().numpy().argmax(axis=1))\n",
    "        recall_label1 += recall_score(batch_label, label_prob1.data.cpu().numpy().argmax(axis=1), average=\"macro\")\n",
    "\n",
    "        gnn_list.extend(gnn_prob.data.cpu().numpy()[:, 1].tolist())\n",
    "        label_list1.extend(label_prob1.data.cpu().numpy()[:, 1].tolist())\n",
    "        \n",
    "        label_actual += batch_label.tolist()\n",
    "        label_prediction += label_prob1.data.cpu().numpy().argmax(axis=1).tolist()\n",
    "        label_index += batch_nodes\n",
    "\n",
    "    auc_gnn = roc_auc_score(labels, np.array(gnn_list))\n",
    "    ap_gnn = average_precision_score(labels, np.array(gnn_list))\n",
    "    auc_label1 = roc_auc_score(labels, np.array(label_list1))\n",
    "    ap_label1 = average_precision_score(labels, np.array(label_list1))\n",
    "    \n",
    "    print(f\"GNN F1: {f1_gnn / test_batch_num:.4f}\")\n",
    "    print(f\"GNN Accuracy: {acc_gnn / test_batch_num:.4f}\")\n",
    "    print(f\"GNN Recall: {recall_gnn / test_batch_num:.4f}\")\n",
    "    print(f\"GNN auc: {auc_gnn:.4f}\")\n",
    "    print(f\"GNN ap: {ap_gnn:.4f}\")\n",
    "    print(f\"Label1 F1: {f1_label1 / test_batch_num:.4f}\")\n",
    "    print(f\"Label1 Accuracy: {acc_label1 / test_batch_num:.4f}\")\n",
    "    print(f\"Label1 Recall: {recall_label1 / test_batch_num:.4f}\")\n",
    "    print(f\"Label1 auc: {auc_label1:.4f}\")\n",
    "    print(f\"Label1 ap: {ap_label1:.4f}\")\n",
    "    \n",
    "    label_dict[\"acc\"][count] = acc_label1 / test_batch_num\n",
    "    label_dict[\"auc\"][count] = auc_label1\n",
    "    \n",
    "    \n",
    "    return label_dict,label_actual,label_prediction,label_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.69086225827535, time: 11.403009414672852s\n",
      "GNN F1: 0.6023\n",
      "GNN Accuracy: 0.8325\n",
      "GNN Recall: 0.5902\n",
      "GNN auc: 0.7207\n",
      "GNN ap: 0.2902\n",
      "Label1 F1: 0.1496\n",
      "Label1 Accuracy: 0.1632\n",
      "Label1 Recall: 0.5078\n",
      "Label1 auc: 0.5914\n",
      "Label1 ap: 0.2119\n",
      "Epoch: 1, loss: 0.6848764419555664, time: 12.169207334518433s\n",
      "epoch scores: [0.001638538940184248, 0.005528446028672483, 0.005875092897748294]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.48, 0.48, 0.48]\n",
      "Epoch: 2, loss: 0.683631420135498, time: 11.739105939865112s\n",
      "epoch scores: [0.0020273738620121312, 0.006851758531114467, 0.00722264747349919]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.45999999999999996, 0.45999999999999996, 0.45999999999999996]\n",
      "Epoch: 3, loss: 0.669084390004476, time: 12.611286163330078s\n",
      "epoch scores: [0.0025911779690577508, 0.008233991199159005, 0.008694856629914746]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.43999999999999995, 0.43999999999999995, 0.43999999999999995]\n",
      "Epoch: 4, loss: 0.6732900937398275, time: 12.655373573303223s\n",
      "epoch scores: [0.0029641304016724233, 0.009301807682641071, 0.009757405827760484]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.41999999999999993, 0.41999999999999993, 0.41999999999999993]\n",
      "Epoch: 5, loss: 0.6715826988220215, time: 11.977411270141602s\n",
      "GNN F1: 0.5520\n",
      "GNN Accuracy: 0.6265\n",
      "GNN Recall: 0.6800\n",
      "GNN auc: 0.7472\n",
      "GNN ap: 0.3374\n",
      "Label1 F1: 0.5786\n",
      "Label1 Accuracy: 0.6810\n",
      "Label1 Recall: 0.6681\n",
      "Label1 auc: 0.7216\n",
      "Label1 ap: 0.3148\n",
      "epoch scores: [0.0033836148555889986, 0.010320851477991593, 0.010864853641792576]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.3999999999999999, 0.3999999999999999, 0.3999999999999999]\n",
      "Epoch: 6, loss: 0.6584397157033285, time: 12.182849884033203s\n",
      "epoch scores: [0.0036507182907450537, 0.011569116486840553, 0.012075012068536728]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.3799999999999999, 0.3799999999999999, 0.3799999999999999]\n",
      "Epoch: 7, loss: 0.6598597367604574, time: 13.60471487045288s\n",
      "epoch scores: [0.004239406116494181, 0.012197235928652945, 0.01283411092080386]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.3599999999999999, 0.3599999999999999, 0.3599999999999999]\n",
      "Epoch: 8, loss: 0.6619796355565389, time: 12.221184968948364s\n",
      "epoch scores: [0.004591894778577005, 0.013047203905999128, 0.01405870626149861]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.33999999999999986, 0.33999999999999986, 0.33999999999999986]\n",
      "Epoch: 9, loss: 0.6582518021265665, time: 12.710291385650635s\n",
      "epoch scores: [0.0054189048439042065, 0.013568005032167181, 0.014306458590255616]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.31999999999999984, 0.31999999999999984, 0.31999999999999984]\n",
      "Epoch: 10, loss: 0.647311290105184, time: 12.894521236419678s\n",
      "GNN F1: 0.5677\n",
      "GNN Accuracy: 0.6467\n",
      "GNN Recall: 0.6923\n",
      "GNN auc: 0.7587\n",
      "GNN ap: 0.3538\n",
      "Label1 F1: 0.5937\n",
      "Label1 Accuracy: 0.7090\n",
      "Label1 Recall: 0.6674\n",
      "Label1 auc: 0.7330\n",
      "Label1 ap: 0.3202\n",
      "epoch scores: [0.004526372239247928, 0.013771433134725238, 0.014935258050867796]\n",
      "rewards: [1, -1, -1]\n",
      "thresholds: [0.33999999999999986, 0.2999999999999998, 0.2999999999999998]\n",
      "Epoch: 11, loss: 0.6532552242279053, time: 11.407015323638916s\n",
      "epoch scores: [0.0061743130807450685, 0.014350238157530804, 0.015389050375445629]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.31999999999999984, 0.2799999999999998, 0.2799999999999998]\n",
      "Epoch: 12, loss: 0.6605960528055826, time: 11.789145231246948s\n",
      "epoch scores: [0.0050469909504697276, 0.01427342593644973, 0.01589620904215075]\n",
      "rewards: [1, 1, -1]\n",
      "thresholds: [0.33999999999999986, 0.2999999999999998, 0.2599999999999998]\n",
      "Epoch: 13, loss: 0.6616091728210449, time: 12.13413381576538s\n",
      "epoch scores: [0.006453351815593598, 0.015589753847513725, 0.015386565545024914]\n",
      "rewards: [-1, -1, 1]\n",
      "thresholds: [0.31999999999999984, 0.2799999999999998, 0.2799999999999998]\n",
      "Epoch: 14, loss: 0.6548964579900106, time: 14.356923341751099s\n",
      "epoch scores: [0.005863171611147079, 0.01577624818011201, 0.01709711376279707]\n",
      "rewards: [1, -1, -1]\n",
      "thresholds: [0.33999999999999986, 0.2599999999999998, 0.2599999999999998]\n",
      "Epoch: 15, loss: 0.6382923126220703, time: 12.867299556732178s\n",
      "GNN F1: 0.5729\n",
      "GNN Accuracy: 0.6515\n",
      "GNN Recall: 0.7001\n",
      "GNN auc: 0.7691\n",
      "GNN ap: 0.3797\n",
      "Label1 F1: 0.5789\n",
      "Label1 Accuracy: 0.6784\n",
      "Label1 Recall: 0.6723\n",
      "Label1 auc: 0.7359\n",
      "Label1 ap: 0.3215\n",
      "epoch scores: [0.00782570914471377, 0.015514539893914379, 0.017024881276335325]\n",
      "rewards: [-1, 1, 1]\n",
      "thresholds: [0.31999999999999984, 0.2799999999999998, 0.2799999999999998]\n",
      "Epoch: 16, loss: 0.6218268076578776, time: 16.486074686050415s\n",
      "epoch scores: [0.006741816384829181, 0.017284623500930935, 0.01885082685426026]\n",
      "rewards: [1, -1, -1]\n",
      "thresholds: [0.33999999999999986, 0.2599999999999998, 0.2599999999999998]\n",
      "Epoch: 17, loss: 0.6585445404052734, time: 13.581292629241943s\n",
      "epoch scores: [0.00825095487884832, 0.017202879996342905, 0.018951067311734616]\n",
      "rewards: [-1, 1, -1]\n",
      "thresholds: [0.31999999999999984, 0.2799999999999998, 0.2399999999999998]\n",
      "Epoch: 18, loss: 0.6481011708577474, time: 13.39371132850647s\n",
      "epoch scores: [0.00748654408014153, 0.018501991743295264, 0.017933991173237507]\n",
      "rewards: [1, -1, 1]\n",
      "thresholds: [0.33999999999999986, 0.2599999999999998, 0.2599999999999998]\n",
      "Epoch: 19, loss: 0.6419340372085571, time: 13.044111728668213s\n",
      "epoch scores: [0.008613021556537257, 0.018833183400874566, 0.02001968851445847]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.31999999999999984, 0.2399999999999998, 0.2399999999999998]\n",
      "Epoch: 20, loss: 0.6393392086029053, time: 11.759159564971924s\n",
      "GNN F1: 0.6236\n",
      "GNN Accuracy: 0.7363\n",
      "GNN Recall: 0.7020\n",
      "GNN auc: 0.7693\n",
      "GNN ap: 0.3766\n",
      "Label1 F1: 0.5960\n",
      "Label1 Accuracy: 0.7119\n",
      "Label1 Recall: 0.6691\n",
      "Label1 auc: 0.7374\n",
      "Label1 ap: 0.3231\n",
      "epoch scores: [0.007430295378862708, 0.018041209471782838, 0.019950895655707523]\n",
      "rewards: [1, 1, 1]\n",
      "thresholds: [0.33999999999999986, 0.2599999999999998, 0.2599999999999998]\n",
      "Epoch: 21, loss: 0.6335121790568033, time: 11.658469915390015s\n",
      "epoch scores: [0.0098569953871157, 0.019889281411012403, 0.021677746044229698]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.31999999999999984, 0.2399999999999998, 0.2399999999999998]\n",
      "Epoch: 22, loss: 0.639625628789266, time: 12.744107007980347s\n",
      "epoch scores: [0.0076642326984781095, 0.019037401902627895, 0.021002457633799015]\n",
      "rewards: [1, 1, 1]\n",
      "thresholds: [0.33999999999999986, 0.2599999999999998, 0.2599999999999998]\n",
      "Epoch: 23, loss: 0.6403954823811849, time: 12.394614458084106s\n",
      "epoch scores: [0.009504806324232402, 0.020142066703786796, 0.02215642577083565]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.31999999999999984, 0.2399999999999998, 0.2399999999999998]\n",
      "Epoch: 24, loss: 0.626486579577128, time: 12.3514564037323s\n",
      "epoch scores: [0.00888116903443967, 0.020208185722175448, 0.022072798783012243]\n",
      "rewards: [1, -1, 1]\n",
      "thresholds: [0.33999999999999986, 0.2199999999999998, 0.2599999999999998]\n",
      "Epoch: 25, loss: 0.6362554232279459, time: 11.913081645965576s\n",
      "GNN F1: 0.5645\n",
      "GNN Accuracy: 0.6372\n",
      "GNN Recall: 0.7003\n",
      "GNN auc: 0.7721\n",
      "GNN ap: 0.3857\n",
      "Label1 F1: 0.5896\n",
      "Label1 Accuracy: 0.6958\n",
      "Label1 Recall: 0.6752\n",
      "Label1 auc: 0.7389\n",
      "Label1 ap: 0.3239\n",
      "epoch scores: [0.01112812709264654, 0.019120705714906098, 0.023988837971400268]\n",
      "rewards: [-1, 1, -1]\n",
      "thresholds: [0.31999999999999984, 0.2399999999999998, 0.2399999999999998]\n",
      "Epoch: 26, loss: 0.6406854391098022, time: 11.20104718208313s\n",
      "epoch scores: [0.008203624369033975, 0.020033833785304943, 0.0228958326297295]\n",
      "rewards: [1, -1, 1]\n",
      "thresholds: [0.33999999999999986, 0.2199999999999998, 0.2599999999999998]\n",
      "Epoch: 27, loss: 0.6245574951171875, time: 11.653867483139038s\n",
      "epoch scores: [0.010947599219442694, 0.02029450023177141, 0.025161084745882033]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.31999999999999984, 0.19999999999999982, 0.2399999999999998]\n",
      "Epoch: 28, loss: 0.6460365454355875, time: 10.883641004562378s\n",
      "epoch scores: [0.009368603476871538, 0.018431850131237857, 0.024384417208992776]\n",
      "rewards: [1, 1, 1]\n",
      "thresholds: [0.33999999999999986, 0.2199999999999998, 0.2599999999999998]\n",
      "Epoch: 29, loss: 0.6220221916834513, time: 11.847561836242676s\n",
      "epoch scores: [0.011359081887672628, 0.020034670080321455, 0.026010011605733255]\n",
      "rewards: [-1, -1, -1]\n",
      "thresholds: [0.31999999999999984, 0.19999999999999982, 0.2399999999999998]\n",
      "Epoch: 30, loss: 0.6384718418121338, time: 12.539876937866211s\n",
      "GNN F1: 0.6131\n",
      "GNN Accuracy: 0.7162\n",
      "GNN Recall: 0.7055\n",
      "GNN auc: 0.7716\n",
      "GNN ap: 0.3819\n",
      "Label1 F1: 0.5897\n",
      "Label1 Accuracy: 0.6949\n",
      "Label1 Recall: 0.6767\n",
      "Label1 auc: 0.7404\n",
      "Label1 ap: 0.3258\n"
     ]
    }
   ],
   "source": [
    "if args.cuda:\n",
    "    gnn_model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, gnn_model.parameters()), lr=args.lr, weight_decay=args.lambda_2)\n",
    "times = []\n",
    "performance_log = []\n",
    "\n",
    "# train the model\n",
    "for epoch in range(args.num_epochs):\n",
    "    # randomly under-sampling negative nodes for each epoch\n",
    "    sampled_idx_train = undersample(train_pos, train_neg, scale=1)\n",
    "    rd.shuffle(sampled_idx_train)\n",
    "\n",
    "    # send number of batches to model to let the RLModule know the training progress\n",
    "    num_batches = int(len(sampled_idx_train) / args.batch_size) + 1\n",
    "    inter1.batch_num = num_batches\n",
    "\n",
    "    loss = 0.0\n",
    "    epoch_time = 0\n",
    "\n",
    "    # mini-batch training\n",
    "    for batch in range(num_batches):\n",
    "        start_time = time.time()\n",
    "        i_start = batch * args.batch_size\n",
    "        i_end = min((batch + 1) * args.batch_size, len(sampled_idx_train))\n",
    "        batch_nodes = sampled_idx_train[i_start:i_end]\n",
    "        batch_label = labels[np.array(batch_nodes)]\n",
    "        optimizer.zero_grad()\n",
    "        if args.cuda:\n",
    "            loss = gnn_model.loss(batch_nodes, Variable(torch.cuda.LongTensor(batch_label)))\n",
    "        else:\n",
    "            loss = gnn_model.loss(batch_nodes, Variable(torch.LongTensor(batch_label)))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        end_time = time.time()\n",
    "        epoch_time += end_time - start_time\n",
    "        loss += loss.item()\n",
    "\n",
    "    print(f'Epoch: {epoch}, loss: {loss.item() / num_batches}, time: {epoch_time}s')\n",
    "    # record\n",
    "    loss_dict[epoch] = loss.item() / num_batches\n",
    "    # testing the model for every $test_epoch$ epoch\n",
    "    # if epoch % args.test_epochs == 0:\n",
    "    if epoch % 5 == 0:\n",
    "        label_dict,usless_x1,usless_x2,usless_x3= test_care(idx_test, y_test, gnn_model, args.batch_size,label_dict,count)\n",
    "        count = count + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print log info of training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss data log:\n",
      "{0: 0.69086225827535, 1: 0.6848764419555664, 2: 0.683631420135498, 3: 0.669084390004476, 4: 0.6732900937398275, 5: 0.6715826988220215, 6: 0.6584397157033285, 7: 0.6598597367604574, 8: 0.6619796355565389, 9: 0.6582518021265665, 10: 0.647311290105184, 11: 0.6532552242279053, 12: 0.6605960528055826, 13: 0.6616091728210449, 14: 0.6548964579900106, 15: 0.6382923126220703, 16: 0.6218268076578776, 17: 0.6585445404052734, 18: 0.6481011708577474, 19: 0.6419340372085571, 20: 0.6393392086029053, 21: 0.6335121790568033, 22: 0.639625628789266, 23: 0.6403954823811849, 24: 0.626486579577128, 25: 0.6362554232279459, 26: 0.6406854391098022, 27: 0.6245574951171875, 28: 0.6460365454355875, 29: 0.6220221916834513, 30: 0.6384718418121338}\n"
     ]
    }
   ],
   "source": [
    "print(\"loss data log:\")\n",
    "print(loss_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc and auc:\n",
      "{'acc': {0: 0.16315488342992623, 1: 0.6809696503751512, 2: 0.7089664239038169, 3: 0.6784378216714475, 4: 0.7118961114038169, 5: 0.6958332342402335, 6: 0.6949347266128088}, 'auc': {0: 0.5913860200067786, 1: 0.7216217353013209, 2: 0.7329911908561818, 3: 0.7359459336475831, 4: 0.737379318428476, 5: 0.7389101934995839, 6: 0.7403764086970914}}\n"
     ]
    }
   ],
   "source": [
    "print(\"acc and auc:\")\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlabel_dict = {'acc': {0: 0.6643965580850213, 1: 0.7036457342402335, 2: 0.7066591935224212, 3: 0.6778372412602934, 4: 0.7124415045808453, 5: 0.6955220056809311, 6: 0.6941390090202162, 7: 0.6941390090202162}, 'auc': {0: 0.6084102566394818, 1: 0.7165546552238516, 2: 0.7287686823818671, 3: 0.7328674531801398, 4: 0.7351667157048617, 5: 0.7370347552884616, 6: 0.7389085464178662, 7: 0.7389085464178662}}\\nloss_dict = {0: 0.6907842953999838, 1: 0.6871467431386312, 2: 0.6824491818745931, 3: 0.6721707185109457, 4: 0.6738455295562744, 5: 0.672266960144043, 6: 0.6608970165252686, 7: 0.6601051886876425, 8: 0.6633611520131429, 9: 0.6575676600138346, 10: 0.648008664449056, 11: 0.6523105303446451, 12: 0.6615211963653564, 13: 0.66359543800354, 14: 0.6559121211369833, 15: 0.6380846500396729, 16: 0.6197942097981771, 17: 0.659347653388977, 18: 0.6474158763885498, 19: 0.6425248781840006, 20: 0.6392460664113363, 21: 0.6330370903015137, 22: 0.6392871538798014, 23: 0.640362024307251, 24: 0.6273306210835775, 25: 0.6368083159128824, 26: 0.6414139270782471, 27: 0.624742348988851, 28: 0.6461329857508341, 29: 0.6221679051717123, 30: 0.6391850312550863}\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save \n",
    "'''\n",
    "label_dict = {'acc': {0: 0.6643965580850213, 1: 0.7036457342402335, 2: 0.7066591935224212, 3: 0.6778372412602934, 4: 0.7124415045808453, 5: 0.6955220056809311, 6: 0.6941390090202162, 7: 0.6941390090202162}, 'auc': {0: 0.6084102566394818, 1: 0.7165546552238516, 2: 0.7287686823818671, 3: 0.7328674531801398, 4: 0.7351667157048617, 5: 0.7370347552884616, 6: 0.7389085464178662, 7: 0.7389085464178662}}\n",
    "loss_dict = {0: 0.6907842953999838, 1: 0.6871467431386312, 2: 0.6824491818745931, 3: 0.6721707185109457, 4: 0.6738455295562744, 5: 0.672266960144043, 6: 0.6608970165252686, 7: 0.6601051886876425, 8: 0.6633611520131429, 9: 0.6575676600138346, 10: 0.648008664449056, 11: 0.6523105303446451, 12: 0.6615211963653564, 13: 0.66359543800354, 14: 0.6559121211369833, 15: 0.6380846500396729, 16: 0.6197942097981771, 17: 0.659347653388977, 18: 0.6474158763885498, 19: 0.6425248781840006, 20: 0.6392460664113363, 21: 0.6330370903015137, 22: 0.6392871538798014, 23: 0.640362024307251, 24: 0.6273306210835775, 25: 0.6368083159128824, 26: 0.6414139270782471, 27: 0.624742348988851, 28: 0.6461329857508341, 29: 0.6221679051717123, 30: 0.6391850312550863}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt loss\n",
    "plt.plot(loss_dict.keys(), loss_dict.values())\n",
    "plt.title(\"Loss of CARE-GNN Training\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt acc\n",
    "plt.plot(label_dict[\"acc\"].keys(), label_dict[\"acc\"].values())\n",
    "plt.title(\"Acc of CARE-GNN Test\")\n",
    "plt.xlabel(\"5*epoch\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt auc\n",
    "plt.plot(label_dict[\"auc\"].keys(), label_dict[\"auc\"].values())\n",
    "plt.title(\"AUC of CARE-GNN Test\")\n",
    "plt.xlabel(\"5*epoch\")\n",
    "plt.ylabel(\"auc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN F1: 0.6131\n",
      "GNN Accuracy: 0.7162\n",
      "GNN Recall: 0.7055\n",
      "GNN auc: 0.7716\n",
      "GNN ap: 0.3819\n",
      "Label1 F1: 0.5897\n",
      "Label1 Accuracy: 0.6949\n",
      "Label1 Recall: 0.6767\n",
      "Label1 auc: 0.7404\n",
      "Label1 ap: 0.3258\n"
     ]
    }
   ],
   "source": [
    "# label_pre\n",
    "label_dict,label_actual,label_prediction,label_index = test_care(idx_test, y_test, gnn_model, args.batch_size,label_dict,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9628\n",
      "4006\n"
     ]
    }
   ],
   "source": [
    "# ensure the number\n",
    "print(np.sum((label_prediction)))\n",
    "print(np.sum((label_actual)))\n",
    "label_pre_class = []\n",
    "for i in label_prediction:\n",
    "    if i == 1:\n",
    "        label_pre_class.append(1)\n",
    "    else:\n",
    "        label_pre_class.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y_pre</th>\n",
       "      <th>y_act</th>\n",
       "      <th>y_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017965</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>0.051368</td>\n",
       "      <td>0.051368</td>\n",
       "      <td>0.020468</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.014073</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049069</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.049835</td>\n",
       "      <td>0.034246</td>\n",
       "      <td>0.048046</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.017370</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.047402</td>\n",
       "      <td>0.047402</td>\n",
       "      <td>0.047402</td>\n",
       "      <td>0.026009</td>\n",
       "      <td>0.039420</td>\n",
       "      <td>0.040060</td>\n",
       "      <td>0.020663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.035139</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>0.018159</td>\n",
       "      <td>0.020518</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042462</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>0.008837</td>\n",
       "      <td>0.049259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.049014</td>\n",
       "      <td>0.049014</td>\n",
       "      <td>0.049014</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>0.023732</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.038893</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.055360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047373</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>0.016250</td>\n",
       "      <td>0.037182</td>\n",
       "      <td>0.022034</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046861</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.023448</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>0.021795</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.007620</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27568</th>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.029360</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.045220</td>\n",
       "      <td>0.033264</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.017636</td>\n",
       "      <td>0.040991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27569</th>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.020911</td>\n",
       "      <td>0.048779</td>\n",
       "      <td>0.048779</td>\n",
       "      <td>0.048779</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.048287</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.027181</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>0.020871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27570</th>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.036436</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.039774</td>\n",
       "      <td>0.033543</td>\n",
       "      <td>0.045242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.045017</td>\n",
       "      <td>0.041640</td>\n",
       "      <td>0.037814</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27571</th>\n",
       "      <td>0.041851</td>\n",
       "      <td>0.012203</td>\n",
       "      <td>0.020350</td>\n",
       "      <td>0.047471</td>\n",
       "      <td>0.047471</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.047471</td>\n",
       "      <td>0.043694</td>\n",
       "      <td>0.007262</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.047235</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.038969</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.006613</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27572</th>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.017625</td>\n",
       "      <td>0.022342</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.033190</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.028004</td>\n",
       "      <td>0.011928</td>\n",
       "      <td>0.023855</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27573 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0      0.017965  0.011535  0.022021  0.051368  0.051368  0.020468  0.026217   \n",
       "1      0.014100  0.017370  0.020321  0.047402  0.047402  0.047402  0.026009   \n",
       "2      0.042462  0.012869  0.021116  0.049258  0.049258  0.049258  0.002402   \n",
       "3      0.007178  0.020437  0.023732  0.055359  0.055359  0.055359  0.038893   \n",
       "4      0.046861  0.016948  0.023448  0.054697  0.054697  0.021795  0.007877   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "27568  0.036923  0.029360  0.047902  0.047902  0.047902  0.047902  0.047902   \n",
       "27569  0.011416  0.020650  0.020911  0.048779  0.048779  0.048779  0.011533   \n",
       "27570  0.028361  0.036436  0.045241  0.045241  0.045241  0.045241  0.022035   \n",
       "27571  0.041851  0.012203  0.020350  0.047471  0.047471  0.018915  0.047471   \n",
       "27572  0.010618  0.017625  0.022342  0.052117  0.052117  0.020767  0.052117   \n",
       "\n",
       "             x8        x9       x10  ...       x26       x27       x28  \\\n",
       "0      0.009174  0.014073  0.051369  ...  0.049069  0.001789  0.005111   \n",
       "1      0.039420  0.040060  0.020663  ...  0.016980  0.031130  0.035139   \n",
       "2      0.005542  0.008837  0.049259  ...  0.004411  0.049014  0.049014   \n",
       "3      0.010172  0.010822  0.055360  ...  0.047373  0.006886  0.013771   \n",
       "4      0.024835  0.005684  0.054697  ...  0.004898  0.054425  0.054425   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "27568  0.045220  0.033264  0.005496  ...  0.014299  0.012631  0.018827   \n",
       "27569  0.018325  0.048287  0.024209  ...  0.021842  0.031549  0.030093   \n",
       "27570  0.039774  0.033543  0.045242  ...  0.004052  0.045017  0.041640   \n",
       "27571  0.043694  0.007262  0.004653  ...  0.004251  0.047235  0.043693   \n",
       "27572  0.016541  0.003461  0.005109  ...  0.041746  0.033190  0.031893   \n",
       "\n",
       "            x29       x30       x31       x32  y_pre  y_act  y_index  \n",
       "0      0.001022  0.049835  0.034246  0.048046      1      0    35042  \n",
       "1      0.010141  0.018159  0.020518  0.015093      0      0    27485  \n",
       "2      0.049014  0.001715  0.006862  0.000490      1      0    16164  \n",
       "3      0.016250  0.037182  0.022034  0.036356      0      0    21204  \n",
       "4      0.054425  0.001905  0.007620  0.007075      1      0    12201  \n",
       "...         ...       ...       ...       ...    ...    ...      ...  \n",
       "27568  0.000238  0.015014  0.017636  0.040991      0      0    38279  \n",
       "27569  0.038829  0.027181  0.015774  0.020871      0      0    16412  \n",
       "27570  0.037814  0.004277  0.006302  0.010354      0      0    25374  \n",
       "27571  0.038969  0.004487  0.006613  0.025507      1      0    22633  \n",
       "27572  0.005445  0.028004  0.011928  0.023855      1      0    28100  \n",
       "\n",
       "[27573 rows x 35 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establish the dataframe\n",
    "# label_pre is predicted label, y_test is actual lable\n",
    "df = pd.DataFrame(feat_data[label_index],columns = [\"x\"+str(i) for i in range(1,33)])\n",
    "df[\"y_pre\"] = label_prediction\n",
    "df[\"y_act\"] = label_actual\n",
    "df[\"y_index\"] = label_index\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.80     23567\n",
      "           1       0.27      0.65      0.38      4006\n",
      "\n",
      "    accuracy                           0.69     27573\n",
      "   macro avg       0.60      0.68      0.59     27573\n",
      "weighted avg       0.83      0.69      0.74     27573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = label_actual\n",
    "y_pred = label_prediction\n",
    "judge = classification_report(y_true, y_pred)\n",
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "classes = [0.0,1.0]\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.imshow(confusion, cmap=plt.cm.Greens)\n",
    "indices = range(len(confusion))\n",
    "plt.xticks(indices, classes)\n",
    "plt.yticks(indices, classes)\n",
    "plt.colorbar()\n",
    "plt.xlabel('y_pred')\n",
    "plt.ylabel('y_true')\n",
    "for first_index in range(len(confusion)):\n",
    "    for second_index in range(len(confusion[first_index])):\n",
    "        plt.text(first_index, second_index, confusion[first_index][second_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df\n",
    "df.to_excel(\"test_result.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import xlwt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "from  sklearn.datasets  import  make_hastie_10_2\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit  \n",
    "from sklearn.preprocessing import StandardScaler    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "      <th>x31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y_pre</th>\n",
       "      <th>y_act</th>\n",
       "      <th>y_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017965</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>0.051368</td>\n",
       "      <td>0.051368</td>\n",
       "      <td>0.020468</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.014073</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049069</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.049835</td>\n",
       "      <td>0.034246</td>\n",
       "      <td>0.048046</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.017370</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.047402</td>\n",
       "      <td>0.047402</td>\n",
       "      <td>0.047402</td>\n",
       "      <td>0.026009</td>\n",
       "      <td>0.039420</td>\n",
       "      <td>0.040060</td>\n",
       "      <td>0.020663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.035139</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>0.018159</td>\n",
       "      <td>0.020518</td>\n",
       "      <td>0.015093</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042462</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.049258</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>0.008837</td>\n",
       "      <td>0.049259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.049014</td>\n",
       "      <td>0.049014</td>\n",
       "      <td>0.049014</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.020437</td>\n",
       "      <td>0.023732</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>0.038893</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.055360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047373</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>0.016250</td>\n",
       "      <td>0.037182</td>\n",
       "      <td>0.022034</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046861</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.023448</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>0.021795</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.054425</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.007620</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27568</th>\n",
       "      <td>0.036923</td>\n",
       "      <td>0.029360</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.045220</td>\n",
       "      <td>0.033264</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.012631</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.017636</td>\n",
       "      <td>0.040991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27569</th>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.020911</td>\n",
       "      <td>0.048779</td>\n",
       "      <td>0.048779</td>\n",
       "      <td>0.048779</td>\n",
       "      <td>0.011533</td>\n",
       "      <td>0.018325</td>\n",
       "      <td>0.048287</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.027181</td>\n",
       "      <td>0.015774</td>\n",
       "      <td>0.020871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27570</th>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.036436</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.045241</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.039774</td>\n",
       "      <td>0.033543</td>\n",
       "      <td>0.045242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.045017</td>\n",
       "      <td>0.041640</td>\n",
       "      <td>0.037814</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27571</th>\n",
       "      <td>0.041851</td>\n",
       "      <td>0.012203</td>\n",
       "      <td>0.020350</td>\n",
       "      <td>0.047471</td>\n",
       "      <td>0.047471</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.047471</td>\n",
       "      <td>0.043694</td>\n",
       "      <td>0.007262</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.047235</td>\n",
       "      <td>0.043693</td>\n",
       "      <td>0.038969</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.006613</td>\n",
       "      <td>0.025507</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27572</th>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.017625</td>\n",
       "      <td>0.022342</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.005109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.033190</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.028004</td>\n",
       "      <td>0.011928</td>\n",
       "      <td>0.023855</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27573 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0      0.017965  0.011535  0.022021  0.051368  0.051368  0.020468  0.026217   \n",
       "1      0.014100  0.017370  0.020321  0.047402  0.047402  0.047402  0.026009   \n",
       "2      0.042462  0.012869  0.021116  0.049258  0.049258  0.049258  0.002402   \n",
       "3      0.007178  0.020437  0.023732  0.055359  0.055359  0.055359  0.038893   \n",
       "4      0.046861  0.016948  0.023448  0.054697  0.054697  0.021795  0.007877   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "27568  0.036923  0.029360  0.047902  0.047902  0.047902  0.047902  0.047902   \n",
       "27569  0.011416  0.020650  0.020911  0.048779  0.048779  0.048779  0.011533   \n",
       "27570  0.028361  0.036436  0.045241  0.045241  0.045241  0.045241  0.022035   \n",
       "27571  0.041851  0.012203  0.020350  0.047471  0.047471  0.018915  0.047471   \n",
       "27572  0.010618  0.017625  0.022342  0.052117  0.052117  0.020767  0.052117   \n",
       "\n",
       "             x8        x9       x10  ...       x26       x27       x28  \\\n",
       "0      0.009174  0.014073  0.051369  ...  0.049069  0.001789  0.005111   \n",
       "1      0.039420  0.040060  0.020663  ...  0.016980  0.031130  0.035139   \n",
       "2      0.005542  0.008837  0.049259  ...  0.004411  0.049014  0.049014   \n",
       "3      0.010172  0.010822  0.055360  ...  0.047373  0.006886  0.013771   \n",
       "4      0.024835  0.005684  0.054697  ...  0.004898  0.054425  0.054425   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "27568  0.045220  0.033264  0.005496  ...  0.014299  0.012631  0.018827   \n",
       "27569  0.018325  0.048287  0.024209  ...  0.021842  0.031549  0.030093   \n",
       "27570  0.039774  0.033543  0.045242  ...  0.004052  0.045017  0.041640   \n",
       "27571  0.043694  0.007262  0.004653  ...  0.004251  0.047235  0.043693   \n",
       "27572  0.016541  0.003461  0.005109  ...  0.041746  0.033190  0.031893   \n",
       "\n",
       "            x29       x30       x31       x32  y_pre  y_act  y_index  \n",
       "0      0.001022  0.049835  0.034246  0.048046      1      0    35042  \n",
       "1      0.010141  0.018159  0.020518  0.015093      0      0    27485  \n",
       "2      0.049014  0.001715  0.006862  0.000490      1      0    16164  \n",
       "3      0.016250  0.037182  0.022034  0.036356      0      0    21204  \n",
       "4      0.054425  0.001905  0.007620  0.007075      1      0    12201  \n",
       "...         ...       ...       ...       ...    ...    ...      ...  \n",
       "27568  0.000238  0.015014  0.017636  0.040991      0      0    38279  \n",
       "27569  0.038829  0.027181  0.015774  0.020871      0      0    16412  \n",
       "27570  0.037814  0.004277  0.006302  0.010354      0      0    25374  \n",
       "27571  0.038969  0.004487  0.006613  0.025507      1      0    22633  \n",
       "27572  0.005445  0.028004  0.011928  0.023855      1      0    28100  \n",
       "\n",
       "[27573 rows x 35 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show df\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 is after feature selection\n",
    "df2 = df.copy()\n",
    "# generate x,y\n",
    "X = df2.drop([\"y_pre\",\"y_index\",\"y_act\"], axis = 1)\n",
    "y = df2['y_pre']\n",
    "# split to train and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train to predict the predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.82432\tval-auc:0.82295\n",
      "[1]\ttrain-auc:0.90440\tval-auc:0.89355\n",
      "[2]\ttrain-auc:0.90719\tval-auc:0.90031\n",
      "[3]\ttrain-auc:0.92595\tval-auc:0.92104\n",
      "[4]\ttrain-auc:0.93157\tval-auc:0.92772\n",
      "[5]\ttrain-auc:0.94053\tval-auc:0.93709\n",
      "[6]\ttrain-auc:0.94925\tval-auc:0.94495\n",
      "[7]\ttrain-auc:0.95427\tval-auc:0.94886\n",
      "[8]\ttrain-auc:0.95404\tval-auc:0.94802\n",
      "[9]\ttrain-auc:0.95456\tval-auc:0.94833\n",
      "[10]\ttrain-auc:0.95734\tval-auc:0.95106\n",
      "[11]\ttrain-auc:0.95993\tval-auc:0.95395\n",
      "[12]\ttrain-auc:0.96385\tval-auc:0.95770\n",
      "[13]\ttrain-auc:0.96556\tval-auc:0.95991\n",
      "[14]\ttrain-auc:0.96648\tval-auc:0.96085\n",
      "[15]\ttrain-auc:0.96656\tval-auc:0.96111\n",
      "[16]\ttrain-auc:0.96906\tval-auc:0.96353\n",
      "[17]\ttrain-auc:0.97028\tval-auc:0.96492\n",
      "[18]\ttrain-auc:0.97206\tval-auc:0.96654\n",
      "[19]\ttrain-auc:0.97488\tval-auc:0.96958\n",
      "[20]\ttrain-auc:0.97661\tval-auc:0.97134\n",
      "[21]\ttrain-auc:0.97656\tval-auc:0.97165\n",
      "[22]\ttrain-auc:0.97869\tval-auc:0.97387\n",
      "[23]\ttrain-auc:0.97952\tval-auc:0.97489\n",
      "[24]\ttrain-auc:0.97955\tval-auc:0.97505\n",
      "[25]\ttrain-auc:0.98021\tval-auc:0.97572\n",
      "[26]\ttrain-auc:0.98031\tval-auc:0.97597\n",
      "[27]\ttrain-auc:0.98173\tval-auc:0.97776\n",
      "[28]\ttrain-auc:0.98226\tval-auc:0.97802\n",
      "[29]\ttrain-auc:0.98337\tval-auc:0.97935\n",
      "[30]\ttrain-auc:0.98283\tval-auc:0.97895\n",
      "[31]\ttrain-auc:0.98377\tval-auc:0.97990\n",
      "[32]\ttrain-auc:0.98447\tval-auc:0.98096\n",
      "[33]\ttrain-auc:0.98458\tval-auc:0.98099\n",
      "[34]\ttrain-auc:0.98517\tval-auc:0.98181\n",
      "[35]\ttrain-auc:0.98531\tval-auc:0.98199\n",
      "[36]\ttrain-auc:0.98592\tval-auc:0.98269\n",
      "[37]\ttrain-auc:0.98660\tval-auc:0.98312\n",
      "[38]\ttrain-auc:0.98685\tval-auc:0.98356\n",
      "[39]\ttrain-auc:0.98733\tval-auc:0.98401\n",
      "[40]\ttrain-auc:0.98779\tval-auc:0.98461\n",
      "[41]\ttrain-auc:0.98836\tval-auc:0.98518\n",
      "[42]\ttrain-auc:0.98869\tval-auc:0.98564\n",
      "[43]\ttrain-auc:0.98915\tval-auc:0.98605\n",
      "[44]\ttrain-auc:0.98960\tval-auc:0.98643\n",
      "[45]\ttrain-auc:0.98947\tval-auc:0.98632\n",
      "[46]\ttrain-auc:0.99005\tval-auc:0.98692\n",
      "[47]\ttrain-auc:0.99062\tval-auc:0.98761\n",
      "[48]\ttrain-auc:0.99092\tval-auc:0.98782\n",
      "[49]\ttrain-auc:0.99101\tval-auc:0.98801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAArg0lEQVR4nO3deZgU9bn28e/DpgjCuAAioxHFiGxOwKhERfAEUcGTmBiFHMMiHsW8KCZxS4xrVGIUhSS+MSEoEYw7i28grjjuRkFHgxjUBCIgAmJGHWTnef+oGmxmpnuqh+6q7uH+XBeXPdVV1fe00L+uX3Xdbe6OiIhIk6QDiIhIYdCAICIigAYEEREJaUAQERFAA4KIiIQ0IIiICKABQSRrZvYzM/tj0jlEcs10HYLEycyWAh2ArSmLv+ruH+7kPs9196d2Ll3xMbNrgS7ufnbSWaT46QhBknCau7dO+dPgwSAXzKxZko/fUMWaWwqXBgQpCGbW1symmNlKM1thZjeYWdPwvkPMbJ6ZrTWzj83sXjMrCe+bBhwI/D8zqzKzy8ysv5ktr7H/pWb2zfD2tWb2sJlNN7PPgJGZHr+OrNea2fTw9kFm5mY2ysyWmdl/zGyMmX3dzN4ys0oz+23KtiPN7EUz+62ZfWpm/zCz/0q5f38ze9TMPjGz983sf2s8bmruMcDPgLPC3/3NcL1RZvaOmX1uZv8ys/NT9tHfzJab2U/MbHX4+45Kub+lmU0ws3+H+V4ws5bhfceY2Uvh7/SmmfVvwP9qKWAaEKRQTAW2AF2ArwEnAeeG9xkwHtgfOBw4ALgWwN1/AHzAl0cdv4r4eN8CHgZKgHvrefwojgYOBc4CJgJXAt8EugNnmtkJNdb9J7AvcA0ww8z2Du+7H1ge/q5nADeZ2Ylpck8BbgIeCH/3I8J1VgNDgDbAKOB2M+udso/9gLZAJ2A0cIeZ7RXedyvQB/gGsDdwGbDNzDoBc4AbwuWXAI+YWbssniMpcBoQJAmzwneZlWY2y8w6AKcCF7v7OndfDdwODAVw9/fd/Ul33+jua4DbgBPS7z6Sl919lrtvI3jhTPv4Ef3C3Te4+xPAOuA+d1/t7iuA5wkGmWqrgYnuvtndHwAWA4PN7ADgWODycF8VwB+B4XXldvf1dQVx9znu/k8PPAs8ARyfsspm4Prw8ecCVcBhZtYEOAcY5+4r3H2ru7/k7huBs4G57j43fOwngfnh8yaNhOYgJQnfTj0BbGZHAc2BlWZWvbgJsCy8vwMwieBFbc/wvv/sZIZlKbe/kunxI1qVcnt9HT+3Tvl5he/4aY5/ExwR7A984u6f17jvyDS562RmpxAceXyV4PfYA/h7yipr3X1Lys9fhPn2BXYnOHqp6SvA98zstJRlzYFn6ssjxUMDghSCZcBGYN8aL1TVbgIc6Onun5jZt4Hfptxf86Ny6wheBAEIzwXUnNpI3aa+x8+1TmZmKYPCgcCjwIfA3ma2Z8qgcCCwImXbmr/rDj+b2W7AIwRHFbPdfbOZzSKYdqvPx8AG4BDgzRr3LQOmufv/1tpKGg1NGUni3H0lwbTGBDNrY2ZNwhPJ1dNCexJMa3wazmVfWmMXq4CDU35+F9jdzAabWXPg58BuO/H4udYeuMjMmpvZ9wjOi8x192XAS8B4M9vdzHoRzPFPz7CvVcBB4XQPQAuC33UNsCU8WjgpSqhw+uwu4Lbw5HZTM+sbDjLTgdPMbFC4fPfwBHVp9r++FCoNCFIohhO8mC0imA56GOgY3ncd0Bv4lODE5owa244Hfh6ek7jE3T8Ffkgw/76C4IhhOZllevxc+xvBCeiPgRuBM9x9bXjfMOAggqOFmcA19Vxf8VD437Vm9np4ZHER8CDB7/F9gqOPqC4hmF56DfgEuBloEg5W3yL4VNMagiOGS9FrSKOiC9NEYmRmIwkuojsu6SwiNWl0FxERQAOCiIiENGUkIiKAjhBERCRU1NchlJSUeJcuXZKOkbV169bRqlWrpGNkTbnjpdzxK9bs2eZesGDBx+5eq3akqAeEDh06MH/+/KRjZK28vJz+/fsnHSNryh0v5Y5fsWbPNreZ/buu5ZoyEhERQAOCiIiENCCIiAigAUFEREIaEEREBNCAICIiIQ0IIiICaEAQEZFQUV+YJiLS2G3YsIF+/fqxceNGtmzZwhlnnMF1113H6NGjmT9/Pu7OXnvtxZw5c2jdunX9O8wg1nI7M3sMOAZ4wd2HpCw34Abge8BW4Hfu/uv69nfgwV28yZmT8hU3b37ScwsT/l58Y7Fyx0u54xdn9qW/HBxpPXdn3bp1tG7dms2bN3PccccxadIkunXrRps2bQD43ve+R58+fbjiiisi7dPMFrj7kTWXx/1/7RaC77o9v8bykcABQFd332Zm7WPOJSJSkMxs+zv/zZs3s3nzZsxs+2Dg7mzatIngffXOycs5BDP7upm9FX7vaisze9vMerj708DndWxyAXB9+J2uuPvqfOQSESlGW7dupaysjPbt2zNw4ECOPvpoAEaNGsV+++3HBx98wIUXXrjTj5O3KSMzuwHYHWgJLHf38eHy/sAlNaaM1gK3AacTfF/rRe7+Xpr9ngecB7Dvvu36XD1xcl7y51OHlrBqfdIpsqfc8VLu+MWZvWentllvU1VVxVVXXcVFF11E586dgWCwmDBhAj179uSUU06JtJ8BAwbEPmV0PcEXdW8g+NLvTHYDNrj7kWb2HeAu4Pi6VnT3PwB/gOAcQjHOVRbrHKtyx0u54xfrOYT/6d+g7V5//XXWrl3LqFGjti9buHAhTz75JDfffPNOZcrnx073AVoDexIcKWSyHJgR3p4J9MpjLhGRorFmzRoqKysBWL9+PU8++SSHHXYY77//PhCcQ3jppZfo2rXrTj9WPofC3wNXAZ2Bm4GxGdadBQwAlgAnAO9GeYCWzZuyOOKZ+kJSXl7e4HcHSVLueCl3/Aox+8qVKxkxYgRbt25l27ZtnHnmmQwePJjjjz+ezz77DHdnv/32Y/LknZ8+z8uAYGbDgc3u/mczawq8ZGYnAtcBXYHWZrYcGO3ujwO/BO41sx8BVcC5+cglIlJsevXqxRtvvFFr+Ysvvrj9dnl5+fZPHe2MvAwI7n4PcE94eytwdHjXvDTrVwLF91ZfRKQRUXWFiIgAGhBERCSkAUFERAANCCIiWdmwYQNHHXUURxxxBN27d+eaa64BYMmSJRx99NF06dKFs846i02bNiWcNHuxlttlYmY38+WJ5V+4+wP1baNyu3gpd7yUO35TT25F//79M66Trmzutttu4zvf+Q5Dhw5lzJgxHHHEEVxwwQWx5C4vL683d6p05XYFcYRgZoOB3kAZwSeSLjGznf8MlYhIjqUrm5s3bx5nnHEGACNGjGDWrFkJpmyY2AeEuorvCAaD59x9i7uvA94CTo47m4hIFDXL5g455BBKSkpo1iw4MiotLWXFihUJp8xe7AOCu78GPErw/Qe/AqYDfwNONrM9zGxfgquWD4g7m4hIFE2bNqWiooLly5fz6quv8o9//CPpSDmR1ETfDsV37r7VzL4OvETQdvoywRfl1FKj7ZSre26JJ3EOdWgZzLMWG+WOl3LHr6qqivLy8qy2Oeigg5g+fTpr1qzh6aefpmnTprz99tu0bNky6301VENy1yWpAaG6+K45QfHdOne/EbgRwMz+TJo+I7WdJke546Xc8YtyUnnNmjU0b96ckpIS1q9fz1VXXcXll1/O2rVrWbNmDUOHDuX+++9n1KhRWZ3o3RnZnlROJ6n/azsU35nZOKDE3deaWS+CttMnEsomIpJWXWVzQ4YMoVu3bgwdOpSf//znfO1rX2P06NFJR81a7ANCXcV3wCDg1vAr4D4Dznb3eo851XYaL+WOl3LHL8q0S7qyuYMPPphXX301D6niE/uAkKH4bm7cWURE5EsFcR2CiIgkTwOCiIgAGhBERCSkAUFERAANCCIi261evZoBAwbQrVs3unfvzqRJQXnmm2++Sd++fenZsyennXYan332WcJJ86Mg2k7NrAz4HdCG4ArlG9V2WniUO17KnTtLI348/ZFHHqFz58707t2bzz//nD59+jBr1ixGjBjBrbfeygknnMBdd93FkiVL+MUvfpHn1NE1qrZT4AtguLt3Jyi1m2hmJclGEpFdzT777EPv3r0B2HPPPTn88MNZsWIF7777Lv369QNg4MCBPPLII0nGzJtCaTtt4e7vAbj7h8BqoF3c2UREqi1dupQ33niDo48+mu7duzN79mwAHnroIZYtW5ZwuvxIZMrIzG4g6DBqCSx39/Ep9x0F/Ano7u7b6tg2tdyuz9UTJ8cTOoc6tIRV65NOkT3ljpdy507PTm0jrVdVVUXr1q1Zv34948aN4+yzz6Zfv3588MEH/OY3v+HTTz/l2GOPZcaMGdsHiEJQnTuqAQMG1DlllNSA0IIv206/EV6xjJl1BMqBEe7+Sn370TmEeCl3vJQ7d6KeQygvL+fYY49lyJAhDBo0iB//+Me11nn33Xc5++yzC6qmotjPIVS3ne5JcKRA+A1pc4ArowwGIiK55u6MHj2aww8/fIfBYPXq1QBs27aNG264gTFjxiQVMa+SGhCq207vJWg7bQHMBO5x94cTyiQiu7iFCxcybdo05s2bR1lZGWVlZcydO5f77ruPr371q3Tt2pX999+fUaNGJR01Lwql7XQo0A/Yx8xGhquOdPeKTPtS22m8lDteyh2/nj17km4afdy4cTGniV8htZ3eE3cWERH5UqFchyAiIgnTgCAiIoAGBBERCWlAEBERoEDK7RpKF6bFS7njpdzRRL3obNmyZQwfPpxVq1ZhZpx33nmMGzeOiooKxowZw4YNG1i/fj3Tpk3jqKOOynPq3Cr2C9NqMbMDzewJM3vHzBaZ2UFJZxKRxqNZs2ZMmDCBRYsW8corr3DHHXewaNEiLrvsMq655hoqKioYNWoUl112WdJRE1NIbz/uIai9ftLMWgO1eoxERBqqY8eOdOzYEdixydTMtn+/wbp169h///2TjJmoJC5M+zowBTgKaAq8CgwDmrn7kwDuXhV3LhHZdaQ2mU6cOJFBgwZxySWXsGHDBubPn590vMQURNsp8A5wLrAJ6Aw8BVxRXXpXY1u1nSZEueOl3NFEbTKtVrPJ9Ne//jVHHHEEJ5xwAn/961956qmnmDBhQp7S5kejajsFTic4avga8AHwADDX3adk2o9OKsdLueOl3NFEPakMsHnz5lpNpm3btqWyshIz45lnnuFb3/pW0X1FZrGfVK7ZdrocqHD3f7n7FmAW0DuhbCLSCKVrMt1///159tlnAXj99dc59NBDk4qYuKTeflS3nXYGbgbGASVm1s7d1wAnAvVO5KncLl7KHS/lzq0XX3yRadOm0bNnT8rKygC46aabmDx5MuPGjWPLli1s2rSJ6dOnJxs0QYXSdnoCcAnwtJkZsAAovpMDIlKwjjvuuLRNpgsWLACCwaxPnz5xxioohdR2CtAr7jwiIhIomAvTREQkWRoQREQE0IAgIiIhDQgikpVly5YxYMAAunXrRvfu3Zk0KbgW6KqrrqJXr16ce+65nHTSSXz44YcJJ5VsxXphmpmVAb8D2gBbCbqLHqixzq+Bc9y93svudGFavJQ7XoV6gdfKlStZuXIlvXv35vPPP6dPnz7MmjWL0tJS2rRpQ3l5OW+99RaLFi3izjvvzHPq3Mr2Aq9CkasL0+L+V/IFMNzd3zOz/YEFZva4u1eGIY8E9oo5k4hkIV1JXLdu3bavs27dOoJPkEsxyduAkKbE7ix3Xwjg7h+a2WqgHVAZXpNwC/B9gioLESlwqSVxAFdeeSWTJ0+mffv2PPPMMwmnk2zldcqoZomdu49Pue8o4E9Ad3ffZmbjgCbufruZVaWbMlK5XXKUO17FVhJXraqqitmzZ7Np0yZGjRqV65h5lW1JXKEoinK7miV21e2lZtYRKAdGuPsr4fTRg0B/d9+SaUBIpXMI8VLueBXqOQSouySuWnl5OQcffDCnnnoqCxcuzHXMvNrVzyHk+1NGNUvsMLM2wBzgSnd/JVzva0AX4H0zWwrsYWbv5zmbiDRAupK49957b/vt2bNn07Vr1yTiyU7I99uPHUrszOzHwEzgHnd/uHold58D7Ff9c3iE0CXP2USkAdKVxE2ZMoXFixezfv16unXrVnSfMJL8nlSuq8RuKNAP2MfMRoarjnT3ioY8htpO46Xc8SrU3OlK4k499VSgeKddJI8DQoYSu3sibFt8Z3VERIqcrlQWERFAA4KIiIQ0IIiICKABQUREQhoQRCQrajttvOJuO30MOAZ4wd2HpCw/EbgVaEHwfcqj3X1LffvTlcrxUu54FeqVymo7LTzFcqVyTbcAP0hdYGZNCDqNhrp7D+DfwIiYc4lIRB07dqR3797Ajm2nbdq02b6O2k6LU17efmRoOn3azPrXWH0fYJO7vxv+/CTw03B7ESlgajttXPI2ZZSu6TQcEC6pnjKy4G3EUuC77j7fzCYBJ7p7zzT7VdtpQpQ7Xmo7jZ/aTvM3IKRrOu1PyoAQLusL/ArYDXgCGOLuZfU9hs4hxEu541Wo5xBAbaeFphjOIdRqOk3H3V929+Pd/SjgOeDdTOuLSHLUdtp45fPtxw5Np8DYdCuaWXt3X21muwGXAzdGeQCV28VLueNVqLnVdtp45eukcq2m0/CjpdcBXYHWZrac4OOljwOXmtkQgiOW37n7vHzkEpGdp7bTxisvA0KGptM6X+jd/VLg0nxkERGRaHSlsoiIABoQREQkFGlAMLNDwhO+mFl/M7vIzErymkxERGIV9QjhEWCrmXUB/gAcAPw5b6lEJKfSFdI99NBDdO/enSZNmjB//vyEU0rSop5U3ubuW8zsdOA37v4bM3sj2wczszLgd0AbYCtwo7s/EN7XGbif4PqFBcAP3H1Tpv2t37yVg66Yk22MxP2k5xZGKndsGnvuKBeUNWvWjAkTJuxQSDdw4EB69OjBjBkzOP/883MRWYpc1COEzWY2jKB07i/hsuYNeLwvgOHu3h04GZiYMvV0M3C7u3cB/gOMbsD+RaQO6QrpDj/8cA477LCE00mhiDogjAL6EryjXxK+m5+WaQMz+7qZvWVmu5tZKzN7G2jh7u8BuPuHwGqgXdhndCLwcLj5n4BvZ//riEh9ahbSiVSL3GVkZi2BA919ceSdpym4C+87iuCFvzuwN/BKeHSAmR0A/DWsw665T5XbJUS54xU1dzaldOkK6S6++GIuuOCCnBwtFGtBHBRv9lyV20U6h2Bmp/HlF9h0Ds8FXO/u/13PptfzZcHdRSn760hwhDHC3bdl05vu7n8gOLHNgQd3cZWWxUe54xU1d9R6i+pCujFjxtQqpCspKaFPnz4ceWSt14isFfOVysWaPVe5o04ZXUvw3QaVAO5eARwcYbtaBXdm1gaYA1zp7q+E660FSsys+m9/KbAiYjYRqUe6QjqRVJFPKrv7pzWWbYuwXXXB3b3AzWEl9kzgHnevPl+AB/NWzwBnhItGALMjZhORelQX0s2bN4+ysjLKysqYO3cuM2fOpLS0lJdffpnBgwczaNCgpKNKgqIeR79tZt8HmprZoQTTPy9l2qCugjtgKNAP2MfMRoarjgyPOC4H7g/PO7xBhG9MU9tpvJQ7XrnMna6QDuD000/PyWNI8Ys6IFwIXAlsJLgg7XHghkwbZCi4uyfN+v8imJYSEZEE1DsghO/u57j7AIJBQUREGqF6zyGE7+63mVl2X7gqIiJFJeqUURXwdzN7ElhXvdDdL0q/iYiIFJOoA8KM8I+IiDRSkT526u5/qutPvsOJSG6o7VSiiHql8hKg1mfW3D3KxWmp+3kMOAZ4wd2HpCy/FzgS2Ay8Cpzv7pvr25/aTuOl3PFS26nELeqUUer17LsD3yPoH8rWLcAeQM2/ffcCZ4e3/wycS1CTLSI50LFjRzp27Ajs2HY6cODAhJNJIYk6ZbQ25c8Kd58IpH1bUlfTqZn1cPengc/r2P9cDxEcIZQ28PcRkXqo7VTSiTpl1DvlxyYERwxpt3X318zsUYKL11oC0919YYTHaQ78ABiXYZ3UtlOu7rklyq9QUDq0DKYDio1yxytq7vLy8sj7rG47Pffcc3n99de3L6+srGTBggVUVVU1JOoOqqqqsspUSIo1e65yR50ympByewuwBDiznm3qbDqtx/8FnnP359OtoLbT5Ch3vNR2Gr9izZ6r3FH/lYwOqyW2C78kJ5PqptPmBOcd1mVa2cyuAdpR+/yCiOwktZ1KFFEHhIeB3nUs65Nhm+qm084EX485Nt2KZnYuMAj4L3eP0qIKqNwubsodr1zmrm477dmzJ2VlZQDcdNNNbNy4kQsvvJA1a9YwePBgysrKePzxx3PymFJ8Mg4IZtaV4BvN2prZd1LuakP4/QZptqvVdGpmJwLXAV2B1ma2nODI43HgTuDfwMvhl+XMcPfrd+L3EpEUajuVKOo7QjgMGAKUAKelLP8c+N90G2VoOp2XZv3im+AVEWlkMr4Qu/tsYLaZ9XX3l2PKJCIiCYj6zvwNM/s/BNNH26eK3P2cvKQSEZHYRf0KzWnAfgQnfp8luHCs1gVmIiJSvKIOCF3c/SpgXVhqN5gvzwuIiEgjEHXKqLportLMegAfAe3zEyk6ldvFS7njlctyu2XLljF8+HBWrVqFmXHeeecxbtw4HnroIa699lreeecdXn311ZxcmCbFK+qA8Acz24vguoJHCS44uzpXIczsK8BMgiOW5sBv3P3OXO1fZFentlOJItKA4O5/DG8+C2RVeR3RSqCvu280s9bAQjN71N0/zMNjiexy1HYqUUQ6h2BmHcxsipn9Nfy5m5mNbsgD1tWECnzV3TeGq+wWNZeIZE9tp5KOpbt6cYeVgoHgbuBKdz/CzJoBb7h7zwY9qNkNBB9fbQksd/fxZnYAMAfoAlzq7nek2Ta17bTP1RMnNyRCojq0hFXrk06RPeWOV9TcPTu1jbzP6rbTs88+m379+m1ffvHFF3PBBRdw2GGHNSTqDqqqqmjduvVO7ycJxZo929wDBgxY4O61ThhFPYewr7s/aGY/BXD3LWa2NfKj11arCdXdlwG9zGx/YJaZPezuq2puqLbT5Ch3vNR2Gr9izZ6r3FGnZtaZ2T6EX6NpZscAn+7E41Y3oe5JjU6k8LzBQuD4ndi/iKRQ26lEEfVt048JPl10iJm9SFBTfcZOPO4OTahm9ktgrbuvDz/NdBxwe307UdtpvJQ7Xmo7lbjV13Z6oLt/4O6vm9kJBGV3Bix2982Zts2wz1pNqASVGLeYmYf7v9Xd/96Q/YtIbWo7lSjqO0KYxZffg/CAu393Zx8wQxOq3paIiCSovnMIlnI7H9cfiIhIgahvQPA0t0VEpJGpb8roCDP7jOBIoWV4m/Bnd/c2eU0nIiKxqe8LcprGFUSkMTnnnHP4y1/+Qvv27Vm4cCEAZ511FosXLwagsrKSkpISKioqEkwpsqOCuVrHzB4DjgFecPchUbZR22m8lDtasyjAyJEjGTt2LMOHD9++7IEHHvgy009+Qtu20a8wFolDwQwIwC3AHoBqF6Xo9evXj6VLl9Z5n7vz4IMPMm9enV8xLpKY2Evk6iq3M7Me7v40+hY22QU8//zzdOjQgUMPPTTpKCI7iFRul/MHraPcLlzeH7gk05SRyu2So9zZFcl99NFH/PSnP+Xuu+/eYfntt99Op06dOPPMMzNuv6sUrRWSYs0ed7ldrtUqt4tK5XbJUe7oRXIQ1Ey3atVqh9KxLVu2cNZZZ7FgwQJKS0szbr+rF60loVizx11ul2tpy+1EGrOnnnqKrl271jsYiCQhqQGhutzuXuDmhDKI5M2wYcPo27cvixcvprS0lClTpgBw//33M2zYsITTidQt9uP/usrtzOxE4DqgK9DazJYDo909Y7+R2k7jpdzR3XfffXUunzp1aqw5RLIR+4CQodxOn8ETEUmQvrtYREQADQgiIhLSgCAiIoAGBBERCRXfVUYpVG4Xr2LNPfXkVpHXraul9Nprr2Xy5Mm0a9cOCL6L+NRTT81LVpEkxXqEYGaPmVmlmf2lxvKpZrbEzCrCP2Vx5hKpNnLkSB577LFay3/0ox9RUVFBRUWFBgNptOI+QsjUaHqpuz8ccx6RHWRqKRVp7PJyhKBGU2lsfvvb39KrVy/OOecc/vOf/yQdRyQv8tZ2mk2jqZlNBfoCG4GngSvcfWOa/artNCHFmrtz26ZZNUHWbCn95JNPaNu2LWbGXXfdxdq1a7n88svzFXe7XaV5s5AUa/ZctZ3mc0BowZeNpt8Ir0pONyB0BD4CWhA0mf7T3a+v7zEOPLiLNzlzUu7D55laQ+M19eRWWTVBLl26lCFDhmw/qRz1vlzb1Zs3k1Cs2bPNbWZ1Dgj5PKkcudHU3Vd6YCNwN3BUHnOJZGXlypXbb8+cOZMePXokmEYkf/L5dq+60bQzQaPp2HQrmllHd19pZgZ8G4j09kvldvEq5txRDRs2jPLycj7++GNKS0u57rrrKC8vp6KiAjPjoIMO4ve//33+wookKC8DQgMaTe81s3aAARXAmHzkEqlPXS2lo0ePTiCJSPzyMiBk22jq7ifmI4eIiESn6goREQE0IIiISEgDgoiIABoQpMCdc845tG/ffoePel566aV07dqVXr16cfrpp1NZWZlcQJFGpKCuMjKzNsAiYJa7p/2YajW1ncYrl7mXRvy48MiRIxk7dizDhw/fvmzgwIGMHz+eZs2acfnllzN+/HhuvvnmnOQS2ZUV2hHCL4Dnkg4hhaNfv37svffeOyw76aSTaNYseC9zzDHHsHz58iSiiTQ6sQ8I6YrvzKwP0AF4Iu5MUrzuuusuTjnllKRjiDQKsU8ZuftrZvYocANB8d10gmmiecDZwDczbV+j3I6re27Jb+A86NAymH4pNrnMnc3Vwx999BHr1q2rtc306dOprKykU6dOGfdXVVWV1eMVCuWOX7Fmz1XupM4hXM+XxXcXAT8E5rr78qC9Ij13/wNBAR4HHtzFi7FsrVhL4nKZO5sKjKVLl9Kq1Y4FdVOnTuXtt9/m6aefZo899si4/a5SWFYoijU3FG/2XOVO6lWpuviuOUHxXV/geDP7Ybi8hZlVufsVCeWTAvbYY4/xq1/9imeffbbewUBEoktqQNih+M7d/6f6DjMbCRypwUCg7rK58ePHs3HjRgYOHAgEJ5bvvPPOhJOKFL/YB4R0xXfuXmfPUSZqO41XErlVNicSnyROKqcrvqu+fyowNe5cIiK7ukK7DkFERBKiAUFERAANCCIiEtKAICIigAYEKXBqOxWJT6yfMjKzx4BjgBfcfUjK8rHAxcAhQDt3/zjK/tR2Gi+1nYo0bnEfIdwC/KCO5S8SdBj9O944UujUdioSn7wMCOkaTd39aeDzmuu7+xvuvjQfWaRxU9upSO7kZcqorkZTd1+Yi32r7TQ5ajuNl3LHr1izF0Pbac1G05xQ22ly1HYaL+WOX7FmL4a205qNpuvy+FiyC1HbqUh+5HNA2KHRFKj3O5KzpXK7eCWRW22nIvHJy4CQrtEUuA7oCrQ2s+XAaHd/3MwuAi4D9gPeMrO57n5uPrJJcVHbqUh88nVSOV2jaZ0V1+7+a+DX+cgiIiLR6EplEREBNCCIiEhIA4KIiAAaECRBdRXXPfTQQ3Tv3p0mTZowf/78BNOJ7HoK4uooMxsA3J6yqCsw1N1nZdpO5XbxipI7amkd1F1c16NHD2bMmMH555/f4Jwi0jAFMSC4+zNAGYCZ7Q28DzyRZCbJv379+rF06dIdlh1++OHJhBGR+KeM0hXfpaxyBvBXd/8i7mwiIruy2I8QIhTfDQVuizuXiMiuLqkpozqL78ysI9ATeDzdhmo7TU6U3Nk2LqZrMq2srGTBggVUVVVlmbK2Xb3BMm7FmhuKN3sxtJ1mkq747kxgprtvTreh2k6TEyV3tl1HdTWZApSUlNCnTx+OPPLILFPWtqs3WMatWHND8WbPVe6kPnZaXXx3L0HxXbVhQO3yGmmUhg0bRt++fVm8eDGlpaVMmTKFmTNnUlpayssvv8zgwYMZNGhQ0jFFdhmxv03NUHz3L+AA4Nmo+1Lbabxynbuu4jqA008/PWePISLRJXFSOV3xHUCnuPOIiEhAVyqLiAigAUFEREIaEEREBNCAICIiIQ0IkrVJkybRo0cPunfvzsSJE5OOIyI5ksTHTh8DjgFecPchKcunAEcCBrwLjHT3jJepqu00d6K2lC5cuJDJkyfz6quv0qJFC04++WSGDBlCly5d8pxQRPItiSOEW4Af1LH8R+5+hLv3Aj4AxsYbS6J45513OProo9ljjz1o1qwZJ5xwAjNmzEg6lojkQN4GhHStpu7+NPB5zfXd/bNwOyMovfN8ZZOG69GjB88//zxr167liy++YO7cuSxbtizpWCKSA+aev9ddM7uBoKuoJbDc3ceHy/sDl6ROGYXL7wZOBRYBg+uqwK5Rbtfn6omT85Y/Xzq0hFXrk06xo56d2ta7TlVVFa1bt2bOnDnMnj2bli1bctBBB9G8eXPGji3cA7rq3MVGueNXrNmzzT1gwIAF7l6rKCzfA0ILvmw1/UZ4ZXLaASG8rynwG+A1d7870/4PPLiLNzlzUq5j510hlttFOYdQV4HWz372M0pLS/nhD3+Yp2Q7b1cvLItbseaG4s2ebW4zq3NAyPc5hOpW0z0JjhTqFQ4a9wPfzWMu2QmrV68G4IMPPmDGjBl8//vfTziRiORCvt+mVreadiZoNa1zXiE8b3CIu78f3v5v4B95ziYN9N3vfpe1a9fSvHlz7rjjDkpKSpKOJCI5kLcBIUOr6XVAV6C1mS0HRgNPAn8yszYEHzt9E7igvsdQ22kynn/++aQjiEge5G1AyNBqOi/NJsfmK4uIiNRPVyqLiAigAUFEREIaEEREBNCAICIiIQ0IIiICaEAQEZGQBgQREQE0IIiISCiv5Xb5ZmafA4uTztEA+wIfJx2iAZQ7Xsodv2LNnm3ur7h7u5oLC6tyM3uL62rsK3RmNl+546Pc8SrW3FC82XOVW1NGIiICaEAQEZFQsQ8If0g6QAMpd7yUO17FmhuKN3tOchf1SWUREcmdYj9CEBGRHNGAICIiQJEOCGZ2spktNrP3zeyKpPNkw8yWmtnfzazCzOYnnScdM7vLzFab2cKUZXub2ZNm9l74372SzFiXNLmvNbMV4XNeYWanJpmxLmZ2gJk9Y2aLzOxtMxsXLi/o5zxD7oJ+zs1sdzN71czeDHNfFy7vbGZ/C19bHjCzFklnTZUh91QzW5LyfJc1aP/Fdg4h/DrOd4GBwHLgNWCYuy9KNFhEZrYUONLdC/riFzPrB1QB97h7j3DZr4BP3P2X4UC8l7tfnmTOmtLkvhaocvdbk8yWiZl1BDq6++tmtiewAPg2MJICfs4z5D6TAn7Ow+9ub+XuVWbWHHgBGAf8GJjh7veb2Z3Am+7+uySzpsqQewzwF3d/eGf2X4xHCEcB77v7v9x9E3A/8K2EMzU67v4c8EmNxd8C/hTe/hPBP/yCkiZ3wXP3le7+enj7c+AdoBMF/pxnyF3QPFAV/tg8/OPAiUD1i2ohPt/pcudEMQ4InYBlKT8vpwj+AqZw4AkzW2Bm5yUdJksd3H1lePsjoEOSYbI01szeCqeUCmrapSYzOwj4GvA3iug5r5EbCvw5N7OmZlYBrAaeBP4JVLr7lnCVgnxtqZnb3auf7xvD5/t2M9utIfsuxgGh2B3n7r2BU4D/E05xFB0P5hqLZb7xd8AhQBmwEpiQaJoMzKw18Ahwsbt/lnpfIT/ndeQu+Ofc3be6exlQSjDz0DXZRNHUzG1mPYCfEuT/OrA30KBpxWIcEFYAB6T8XBouKwruviL872pgJsFfxGKxKpwzrp47Xp1wnkjcfVX4j2gbMJkCfc7DOeFHgHvdfUa4uOCf87pyF8tzDuDulcAzQF+gxMyqO94K+rUlJffJ4dSdu/tG4G4a+HwX44DwGnBo+GmAFsBQ4NGEM0ViZq3CE2+YWSvgJGBh5q0KyqPAiPD2CGB2glkiq35BDZ1OAT7n4cnCKcA77n5byl0F/Zyny13oz7mZtTOzkvB2S4IPqbxD8AJ7RrhaIT7fdeX+R8qbBiM479Gg57voPmUEEH6EbSLQFLjL3W9MNlE0ZnYwwVEBBE2zfy7U7GZ2H9CfoFZ3FXANMAt4EDgQ+DdwprsX1AncNLn7E0xdOLAUOD9lXr4gmNlxwPPA34Ft4eKfEczHF+xzniH3MAr4OTezXgQnjZsSvDF+0N2vD/+N3k8w7fIGcHb4rrsgZMg9D2gHGFABjEk5+Rx9/8U4IIiISO4V45SRiIjkgQYEEREBNCCIiEhIA4KIiAAaEEREJNSs/lVEdi1mtpXgY5TVvu3uSxOKIxIbfexUpAYzq3L31jE+XrOU/hyRxGjKSCRLZtbRzJ4Le+cXmtnx4fKTzez1sKv+6XDZ3mY2KywdeyW8sKj6+wKmmdmLwLTwCtRHzOy18M+xCf6KsovSlJFIbS3DNkmAJe5+eo37vw887u43ht/PsYeZtSPo7Onn7kvMbO9w3euAN9z922Z2InAPwRW8AN0Iyg7Xm9mfgdvd/QUzOxB4HDg8b7+hSB00IIjUtj5sk0znNeCusNRtlrtXmFl/4Dl3XwKQUi9xHPDdcNk8M9vHzNqE9z3q7uvD298EugVVNAC0MbPWDakfEGkoDQgiWXL358La8sHAVDO7DfhPA3a1LuV2E+AYd9+Qi4wiDaFzCCJZMrOvAKvcfTLwR6A38ArQz8w6h+tUTxk9D/xPuKw/8HHN7zkIPQFcmPIYZXmKL5KWjhBEstcfuNTMNhN8f/Nwd18TfgPeDDNrQvC9BQOBawmml94CvuDLKuuaLgLuCNdrBjxH8D25IrHRx05FRATQlJGIiIQ0IIiICKABQUREQhoQREQE0IAgIiIhDQgiIgJoQBARkdD/B8ZhKGhJJiejAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model \n",
    "pre_model = None\n",
    "\n",
    "data_train = xgb.DMatrix(X_train, y_train)  # 使用XGBoost的原生版本需要对数据进行转化\n",
    "data_val = xgb.DMatrix(X_val, y_val)\n",
    "param = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',  # multi-classification algorithm\n",
    "    #'objective': 'binary:logistic', # binary-classification algorithm\n",
    "    #'num_class': 7,               # set number of classes needed to classify, if using the softmax function, it needed to be set\n",
    "    'gamma': 0.2,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree.Generally setting 0.1,0.2\n",
    "    'max_depth': 3,               # Maximum depth of a tree. Increasing value will make more complex and may likely to overfit\n",
    "    'lambda': 0.4,                 # L2 regularization term on weights. Can avoid the model overfitting.\n",
    "    'alpha':12,                    # L1 regularization term on weights. Increasing this value will make model more conservative.\n",
    "    'subsample': 0.2,              # ratio of the training instances.  Randomly sample of the training data by using this ratio and prior to growing trees. It used to prevent overfitting.\n",
    "    'colsample_bytree': 0.5,       # the subsample ratio of columns when constructing each tree\n",
    "    'min_child_weight': 1,         # Minimum sum of instance weight (hessian) needed in a child\n",
    "    \"max_delta_step\":0,            # Maximum delta step we allow each leaf output to be\n",
    "    'eta': 0.2,                    # it seems like learning rate.\n",
    "    #\"scale_pos_weight\":1,         #benifit converge quickly in unbalance situation\n",
    "    'silent': 0,                   # if setting on 1, it would no have executed information output, the better way is set to 0\n",
    "    'nthread': 4,                  # Number of parallel threads used to run XGBoost\n",
    "    #\"min_child_weight\":1,          #minimum subtree\n",
    "    \"eval_metric\": [\"auc\"] #can combine to use the function of evaluate the data.\n",
    "}\n",
    "\n",
    "watchlist = [(data_train, 'train'),(data_val, 'val')]\n",
    "n_round = 50\n",
    "evals_result={}\n",
    "booster = xgb.train(param, data_train,num_boost_round = n_round,evals = watchlist,xgb_model = pre_model,evals_result=evals_result)\n",
    "\n",
    "# get importance\n",
    "plot_importance(booster,\n",
    "                 height=0.5,\n",
    "                 max_num_features=15)\n",
    "\n",
    "# save the model\n",
    "#booster.save_model('./model/xgb.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train to predict the incorrected predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 is after feature selection\n",
    "df2 = df.copy()\n",
    "df2[\"judge_false\"] = abs(df2[\"y_pre\"] - df2[\"y_act\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 is after feature selection\n",
    "# generate x,y\n",
    "X = df2.drop([\"y_pre\",\"y_index\",\"y_act\",\"judge_false\"], axis = 1)\n",
    "y = df2['judge_false']\n",
    "# split to train and test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:32:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.73961\tval-auc:0.72479\n",
      "[1]\ttrain-auc:0.78562\tval-auc:0.77605\n",
      "[2]\ttrain-auc:0.79332\tval-auc:0.78522\n",
      "[3]\ttrain-auc:0.80665\tval-auc:0.79894\n",
      "[4]\ttrain-auc:0.80542\tval-auc:0.79756\n",
      "[5]\ttrain-auc:0.82285\tval-auc:0.81493\n",
      "[6]\ttrain-auc:0.82477\tval-auc:0.81470\n",
      "[7]\ttrain-auc:0.83124\tval-auc:0.82149\n",
      "[8]\ttrain-auc:0.83421\tval-auc:0.82489\n",
      "[9]\ttrain-auc:0.83679\tval-auc:0.82737\n",
      "[10]\ttrain-auc:0.83798\tval-auc:0.82861\n",
      "[11]\ttrain-auc:0.84006\tval-auc:0.83124\n",
      "[12]\ttrain-auc:0.84295\tval-auc:0.83293\n",
      "[13]\ttrain-auc:0.84571\tval-auc:0.83519\n",
      "[14]\ttrain-auc:0.84681\tval-auc:0.83623\n",
      "[15]\ttrain-auc:0.84876\tval-auc:0.83820\n",
      "[16]\ttrain-auc:0.85022\tval-auc:0.83939\n",
      "[17]\ttrain-auc:0.85197\tval-auc:0.84154\n",
      "[18]\ttrain-auc:0.85294\tval-auc:0.84247\n",
      "[19]\ttrain-auc:0.85471\tval-auc:0.84428\n",
      "[20]\ttrain-auc:0.85565\tval-auc:0.84522\n",
      "[21]\ttrain-auc:0.85624\tval-auc:0.84548\n",
      "[22]\ttrain-auc:0.85758\tval-auc:0.84695\n",
      "[23]\ttrain-auc:0.85788\tval-auc:0.84712\n",
      "[24]\ttrain-auc:0.85803\tval-auc:0.84730\n",
      "[25]\ttrain-auc:0.85873\tval-auc:0.84823\n",
      "[26]\ttrain-auc:0.85902\tval-auc:0.84841\n",
      "[27]\ttrain-auc:0.86056\tval-auc:0.84960\n",
      "[28]\ttrain-auc:0.86119\tval-auc:0.85008\n",
      "[29]\ttrain-auc:0.86152\tval-auc:0.85000\n",
      "[30]\ttrain-auc:0.86191\tval-auc:0.85033\n",
      "[31]\ttrain-auc:0.86249\tval-auc:0.85056\n",
      "[32]\ttrain-auc:0.86269\tval-auc:0.85053\n",
      "[33]\ttrain-auc:0.86343\tval-auc:0.85091\n",
      "[34]\ttrain-auc:0.86399\tval-auc:0.85112\n",
      "[35]\ttrain-auc:0.86437\tval-auc:0.85156\n",
      "[36]\ttrain-auc:0.86474\tval-auc:0.85178\n",
      "[37]\ttrain-auc:0.86474\tval-auc:0.85162\n",
      "[38]\ttrain-auc:0.86550\tval-auc:0.85232\n",
      "[39]\ttrain-auc:0.86561\tval-auc:0.85229\n",
      "[40]\ttrain-auc:0.86598\tval-auc:0.85231\n",
      "[41]\ttrain-auc:0.86628\tval-auc:0.85254\n",
      "[42]\ttrain-auc:0.86664\tval-auc:0.85299\n",
      "[43]\ttrain-auc:0.86703\tval-auc:0.85331\n",
      "[44]\ttrain-auc:0.86757\tval-auc:0.85373\n",
      "[45]\ttrain-auc:0.86764\tval-auc:0.85339\n",
      "[46]\ttrain-auc:0.86775\tval-auc:0.85359\n",
      "[47]\ttrain-auc:0.86844\tval-auc:0.85393\n",
      "[48]\ttrain-auc:0.86866\tval-auc:0.85424\n",
      "[49]\ttrain-auc:0.86868\tval-auc:0.85429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAArq0lEQVR4nO3deZwU9bnv8c+DCCKLBAUcwH1DYXQCuHBUFg2uuB0TlXMM4GCi9xwiiQHFeGMUl4BKgppcvTEoqGiMURmvEpcgGDUSAUVFPaBRIiCriDIEkYHn/lE12AzdM91Dd1dX8X2/XvOiu7q6+nnScX5Tv6r6lrk7IiIiTaIuQERESoMGBBERATQgiIhISAOCiIgAGhBERCSkAUFERAANCCI5M7Ofmdnvo65DJN9M1yFIMZnZIqAjsDll8aHu/ukObvNSd//LjlUXP2Z2PXCwu18cdS0Sf9pDkCic5e6tUn4aPRjkg5k1jfLzGyuudUvp0oAgJcHM9jCziWa2zMyWmtlNZrZL+NpBZvaimX1mZqvNbIqZtQ1fexDYF/h/ZlZtZleZWT8zW1Jn+4vM7Dvh4+vN7E9m9pCZfQkMre/z09R6vZk9FD7e38zczC4xs8Vm9rmZXW5mR5vZ22a21sx+k/LeoWb2qpn9xsy+MLP/MbOTU17vZGZPmdkaM/vQzH5Q53NT674c+BlwYdj7W+F6l5jZ+2a2zsw+MrPLUrbRz8yWmNlPzWxl2O8lKa+3MLPxZvbPsL5XzKxF+NpxZva3sKe3zKxfI75qKWEaEKRUTAJqgIOBbwOnAJeGrxnwS6ATcDiwD3A9gLt/H/iEb/Y6bs3y884B/gS0BaY08PnZOBY4BLgQmABcC3wH6AZcYGZ966z7D2Av4BfAE2bWLnztD8CSsNfvAreY2UkZ6p4I3AI8GvZ+VLjOSmAg0Aa4BPi1mfVI2cbewB5AZ2AY8Fsz+1b42u1AT+DfgHbAVcAWM+sMPAPcFC4fCTxuZu1z+N9ISpwGBInC1PCvzLVmNtXMOgJnAD929/XuvhL4NXARgLt/6O4vuPtGd18F/Arom3nzWXnN3ae6+xaCX5wZPz9LN7r7V+7+PLAeeMTdV7r7UuBlgkGm1kpggrtvcvdHgQXAmWa2D3A8cHW4rXnA74HB6ep29w3pCnH3Z9z9Hx54CXgeODFllU3AmPDzpwHVwGFm1gSoBEa4+1J33+zuf3P3jcDFwDR3nxZ+9gvAnPB/N0kIzUFKFM5NPQBsZscAuwLLzKx2cRNgcfh6R+AOgl9qrcPXPt/BGhanPN6vvs/P0oqUxxvSPG+V8nypb3s2xz8J9gg6AWvcfV2d13plqDstMzudYM/jUII+dgfeSVnlM3evSXn+r7C+vYDdCPZe6toP+J6ZnZWybFdgRkP1SHxoQJBSsBjYCOxV5xdVrVsAB8rdfY2ZnQv8JuX1uqfKrSf4JQhAeCyg7tRG6nsa+vx862xmljIo7As8BXwKtDOz1imDwr7A0pT31u11m+dm1hx4nGCvosrdN5nZVIJpt4asBr4CDgLeqvPaYuBBd//Bdu+SxNCUkUTO3ZcRTGuMN7M2ZtYkPJBcOy3UmmBa44twLntUnU2sAA5Meb4Q2M3MzjSzXYH/DTTfgc/Ptw7AFWa2q5l9j+C4yDR3Xwz8Dfilme1mZkcSzPE/VM+2VgD7h9M9AM0Iel0F1IR7C6dkU1Q4fXYf8Kvw4PYuZtY7HGQeAs4ys1PD5buFB6i75N6+lCoNCFIqBhP8MnuPYDroT0BZ+NoNQA/gC4IDm0/Uee8vgf8dHpMY6e5fAP9FMP++lGCPYQn1q+/z8+3vBAegVwM3A99198/C1wYB+xPsLTwJ/KKB6yseC//9zMzeCPcsrgD+SNDHfxDsfWRrJMH00mxgDTAOaBIOVucQnNW0imCPYRT6HZIoujBNpIjMbCjBRXQnRF2LSF0a3UVEBNCAICIiIU0ZiYgIoD0EEREJxfo6hLZt2/rBBx8cdRl5t379elq2bBl1GQWR1N7UV/wktbds+po7d+5qd98udiTWA0LHjh2ZM2dO1GXk3cyZM+nXr1/UZRREUntTX/GT1N6y6cvM/pluuaaMREQE0IAgIiIhDQgiIgJoQBARkZAGBBERATQgiIhISAOCiIgAGhBERCSkAUFEJAYWL15M//79OeKII+jWrRt33HEHAPPmzeO4446joqKCXr168f777zf6M0om3M7M9iW4ock+BLcFPMPdF9X3nn0PPNibXHBHEaorrp+W1zD+nVhfRJ5RUntTX/ETdW+Lxp6Z0/rLli1j2bJl9OjRg3Xr1tGzZ0+mTp3Kj3/8Y37yk59w+umnM23aNH72s58xb968erdlZnPdvVfd5aX0TT8A3OzuL5hZK2BL1AWJiJSKsrIyysqCm/i1bt2aww8/nKVLl2JmfPnllwB88cUX7Lnnno3+jKIPCGZ2NDAROAbYBXid4LaBTd39BQB3ry52XSIicbFo0SLefPNNjj32WCZMmMCpp57KyJEj2bJlC+PHj2/0diOZMjKzm4DdgBYE97p9H7gU+Bo4APgLMNrdN6d57w+BHwLstVf7ntdNuLdYZRdNxxawYkPUVRRGUntTX/ETdW/lnfdo1Ps2bNjAiBEjuPjii+nTpw933nknRx11FH379mXGjBlUVVUxYcKEerfRv3//tFNGUQ0IzQhu4v0V8G/AeQR7Dd8GPgEeBaa5+8T6tqNjCPGT1N7UV/xE3VuuxxAANm3axMCBAzn11FO58sorAdhjjz1Yu3YtZoa706pVK9avX1/vdjIdQ4jqLKM9gVZAa4I9hSXAPHf/yN1rgKlAj4hqExEpOe7OsGHDOPzww7cOBgCdOnXipZdeAuDFF1+kc+fOjf6MqPYQngL+QDA9VAaMAN4AvuPuq8zsfmCOu/+2vu0cdthhvmDBgoLXW2xJzWmH5PamvuInbr298sornHjiiZSXl9OkSfC3/C233EKbNm0YMWIENTU17LbbblRWVnLZZZfVu62SOcvIzAYDm9z9YTPbBfgb0BcYCUw3MwPmAsk7OCAi0kgnnHACmf6Anzt37tbHM2fObPRnFH1AcPcHCE4xJTxofGzKy0cWux4REQnoSmUREQE0IIiISEgDgoiIABoQRETyKlMIHcBdd91F165d6datG1dddVWEVaZX1IPKZvYscBzwirsPTFluwE3A94DNwN3ufmdD29uwaTP7j36mUOVG5qflNQxNYF+Q3N7UV/xk21uuF5A1bdqU8ePHbxNCN2DAAFasWEFVVRVvvfUWzZs3Z+XKlY0tvWCKfZbRbcDuQN2TZIcSpJx2dfctZtahyHWJiORFphC6e++9l9GjR9O8eXMAOnQovV9zBZkyMrOjzextM9vNzFqa2btm1t3dpwPr0rzlfwFj3H0LgLuX3tApIpKj1BC6hQsX8vLLL3PsscfSt29fZs+eHXV52ynIHoK7zw6vRr6JIMDuIXefX89bDgIuNLPzgFXAFe7+QSFqExEphurqas4//3wmTJhAmzZtqKmpYc2aNcyaNYvZs2dzwQUX8NFHHxHMmJeGQk4ZjeGbALsrGli3OfCVu/cys38H7gNOTLdinbRTriuvyV/FJaJji2B+M4mS2pv6ip9se2vMlb81NTVcc801HHvssbRr146ZM2ey++67c+CBB27NHfr666+pqqqibdu2OW+/PtXV1Y2+WrmQA0JtgN2uBAF29cXvLQGeCB8/CdyfaUV3/x3wOwjSTpOYxBh1CmMhJbU39RU/2fa26D/75bRdd2fIkCEcf/zx28RQV1ZW8umnn9KvXz8WLlxIkyZNOOecc/K+h7AjGU2F/Kb/L/BzggC7ccDwetadCvQHPibINVpYwLpERArm1Vdf5cEHH6S8vJyKigogCKGrrKyksrKS7t2706xZMyZPnlxS00VAMJrl+wcYDDwePt4F+DtwEvAywTGCDQR7BaeG67QFngHeAV4Djsrmcw499FBPohkzZkRdQsEktTf1FT9J7S2bvgjSpLf7nVqog8qZAuxezLD+WiD3u0WIiEje6EplEREBNCCIiEhIA4KIiAAaEEREJKQBQURKXqYE0VGjRtG1a1eOPPJIzjvvPNauXRttoTFnnuEencWWKQm1PvseeLA3ueCOhleMGV0MFD/qKze5JoguW7aMZcuWbZMgOnXqVJYsWcJJJ51E06ZNufrqqwEYN25cVtvckQu4Slk2fZnZXHfvVXd5Ke0h3AZ8P+oiRKT0lJWV0aNHD2DbBNFTTjmFpk2DAeu4445jyZIlUZYZe0UfEBqRhCoislVqgmiq++67j9NPPz2iqpIhkikjM7uJIN+oBbDE3X8ZLu8HjKxvyqhOuF3P6ybcW/B6i61jC1ixIeoqCiOpvamv3JR33qNR79uwYQMjRozg4osvpk+fPluXP/TQQyxYsIAxY8ZkHQdRXV1Nq1atGlVHKcumr/79+6edMopq0jOXJNRtuMLtYi2pvamv3OQaGAewadMmBg4cyOWXX86VV165dfmkSZN49913mT59OrvvvnvW29uZjyFkEtX/g3NJQhWRnZy7M2zYMA4//PBtBoNnn32WW2+9lZdeeimnwUDSi2pAyCUJVUR2cpkSRK+44go2btzIgAEDgODA8j333BNhpfFW9AHBzAYDm9z9YTPbBfibmZ0E3AB0BVqZ2RJgmLs/V9+2Wuy6CwtyPH0tDmbOnNmoXeo4SGpv6quwTjjhBNId7zzjjDMiqCa5ij4g5JqEKiIixVFK1yGIiEiENCCIiAigAUFEREIaEEREBIjutNO82LBpM/uPfibqMvLup+U1DE1gX5Dc3tRX7oF1ixcvZvDgwaxYsQIz44c//CEjRozgscce4/rrr+f999/n9ddfp1ev7S6olQIpiT0EM6sws9fCXKO3zezCqGsSkcJq2rQp48eP57333mPWrFn89re/5b333qN79+488cQT20RTSHGUyh7Cv4DB7v6BmXUC5prZc+6+NuK6RKRAysrKKCsrA7ZNMK29yEyKryTSToFm7v4BgLt/CqwE2he7NhGJRqYEUymuKC5Mm21mTwE3EaSdPuTu82tfN7NjgGbAP9K9v07aKdeV1xS+6CLr2CKYu02ipPamvoKrmhujNsH00ksv5Y033ti6fO3atcydO5fq6upGbbch1dXVja65lO1IXyWVdmpmZcCDwBB335LujUo7jbek9qa+8ptgCtC2bVt69uxZsIPKSjvdXlQHlWvTTlsTpJ1iZm2AZ4Br3X1WRHWJSJFkSjCV6JRE2qmZXQk8CTzg7n/KdiMKt4ufpPamvnKXKcF048aN/OhHP2LVqlWceeaZVFRU8Nxz9eZcSp6URNopcBHQB9jTzIaGqw5193nFrk9EiiNTginAeeedV+RqBEor7fSBYtciIiLfKIkL00REJHoaEEREBNCAICIiIQ0IIhKJxYsX079/f4444gi6devGHXfcAcBjjz1Gt27daNKkCXPmzIm4yp1LyVxJY2bjgNpzSG9090cbeo/STuMnqb2pr9zTTmvD7Xr06MG6devo2bMnAwYM2Bpud9lllzWmZNkBJTEgmNmZQA+gAmgOzDSzP7v7l5EWJiIFo3C70lMq4XY9gL+6e427rwfeBk4rdm0iEg2F25WGkgi3A+YCvzCz8cDuQH/gvXTvV7hdvCW1N/WlcLtSEftwO3ffbGZHE1y1vAp4Ddic7o0Kt4u3pPamvhRuVyoSEW7n7je7e4W7DwAMWBhRbSJSBAq3Kz1RDQi14XZTCMLtdjGzPQHM7EjgSOD5iGoTkSKoDbd78cUXqaiooKKigmnTpvHkk0/SpUsXXnvtNc4880xOPfXUqEvdaZRKuN2pwO1mBvAlcLG7NzhxqbTT+Elqb+ordwq3Kz2lFG43rdi1iIjIN3SlsoiIABoQREQkpAFBREQADQgiIhLSgCAieZMpwXTNmjUMGDCAQw45hAEDBvD5559HXKmkU9SzjMzsWeA44BV3H5iyfArQC9gEvA5c5u6bGtqe0k7jJ6m9JbWvSae1zGn9TAmmkyZN4uSTT2b06NGMHTuWsWPHMm7cuAJVLY1V7D2E24Dvp1k+BegKlBPkG11azKJEJD/Kysro0aMHsG2CaVVVFUOGDAFgyJAhTJ06NcIqJZOCDAjpEk3NrLu7TwfW1V3f3ad5iGAPoUsh6hKR4klNMF2xYsXWqOu9996bFStWRFydpFOQKaN0iabuPr+h95nZrgR7ECPqWUdppzGW1N6S2ldjkzPrJpjW1NRss53NmzdHnjSqtNPtFfIYwjaJplm+5/8Q3Bfh5UwrKO003pLaW1L7mnRay5yTM9MlmHbu3JnDDjuMsrIyli1bRqdOnSJPGlXa6fYKeQxhu0TT+pjZL4D2gGIPRWIqU4Lp2WefzeTJkwGYPHky55xzTlQlSj0K+SdNbaLpAcA4YHimFc3sUoKAu5PdfUu2H6Bwu/hJam9J7isXtQmm5eXlVFRUAHDLLbcwevRoLrjgAiZOnMh+++3HH//4x/wXKzusIANCukRTMzsJuIHgbKJWZrYEGObuzwH3AP8EXgsTT59w9zGFqE1ECqe+BNPp06cXuRrJVaEOKmdKNH0xw/rJm3wVEYkZXaksIiKABgQREQllNSCY2UFm1jx83M/MrjCztgWtTEREiirbPYTHgc1mdjDBNQD7AA8XrCoRKRmVlZV06NCB7t27b1321ltv0bt3b8rLyznrrLP48ssvI6xQ8sUynRGwzUpmb7h7DzMbBXzl7neZ2Zvu/u2cPixzuN1JwO1AM2AuwdlHDV72ue+BB3uTC+7IpYRYSOpFTpDc3uLU16IcTtWeOXMmTZo0oVWrVgwePJj584PAgaOPPprbb7+dvn37ct999/Hxxx9z4403FqrkgtiZL0wzs7nu3qvu8mz3EDaZ2SBgCPB0uGzXXIoMbRduZ2ZNgMnARe7eneD00yGN2LaIFECfPn1o167dNssWLlxInz59ABgwYACPP/54FKVJnmU7IFwC9AZudvePzewA4MFMK+cYbrcn8LW7LwyfvwCcn2MfIlJE3bp1o6qqCoDHHnuMxYsXR1yR5ENWU0YAZtYC2NfdF2S5/k0EkRUtgCXu/stweT9gZO2UkQVXoi0Cznf3OWZ2B3CSu5dn2G5quF3P6ybcm1X9cdKxBazYEHUVhZHU3uLUV3nnPbJet7q6mlatWrF8+XKuueYa7r//fgA++eQT7rrrLr744guOP/54nnjiia0DRFzU9pY02fTVv3//tFNGWU16mtlZfDPHf4CZVQBj3P3set6WVbidu7uZXQT8OjyT6Xlgcz3rK9wuxpLaW5z6yiVio3Y+etGiRbRsuW3Q3eDBg4Fg+ujdd9+N3Xz8znwMIZNsp4yuB44B1gK4+zzgwAbek3W4nbu/5u4nuvsxwF+BhfWtLyLRWrlyJQBbtmzhpptu4vLLL4+4IsmHrA8qu/sXdZY1FEJXG243hSDcLiMz6xD+2xy4miDbSERKwKBBg+jduzcLFiygS5cuTJw4kUceeYRDDz2Url270qlTJy655JKoy5Q8yHYf910z+w9gFzM7hGAK6G+ZVm5EuN0oMxtIMEDd7e5pM4/qUtpp/CS1t6T2BfDII4+kXT5iRMb7WElMZTsg/Ai4FthIcEHacwR3Q0urEeF2o4BRWdYiIiIF0OCAEP6F/4y79ycYFEREJIEaPIYQ/oW/xcyyP1dNRERiJ9spo2rgHTN7AVhfu9Dds71XsoiIlLhsB4Qnwh8REUmorE47dffJ6X4KXZyIpE8bBbjrrrvo2rUr3bp146qrroqoOkmSbK9U/hjYLuPC3Ru6OC0rZrYf8CTBALUrcJe7N3gtwoZNm9l/9DP5KKGk/LS8hqEJ7AuS21sufeWSNgowdOhQhg8fvvXKYIAZM2ZQVVXFW2+9RfPmzbdeKCayI7KdMkrNvNgN+B7QLsO6jbEM6O3uG82sFTDfzJ5y90/z+BkisdSnTx8WLVq0zbK7776b0aNH07x5cwA6dOgQQWWSNNlOGX2W8rPU3ScAjboiLF0SKnCou28MV2mebV0iO6uFCxfy8ssvc+yxx9K3b19mz54ddUmSANlOGfVIedqEYI+hUUle7j7bzJ4iuLCtBfCQu883s32AZ4CDgVGZ9g7qpJ1yXXmD99GJnY4tgimIJEpqb7n0NXPmzJy3v3z5ctavX7/1vV988QXvvPMOY8eO5X/+5384++yzefjhhwnCg/Onurq6UfXGQVJ725G+sr1j2oyUpzXAx8D4bKOw02yvGd8kof5beK1D7WudgKnAWe6+or7t6I5p8ZPU3nLpK9djCACLFi1i4MCBW+9Ydtppp3H11VfTv39/AA466CBmzZpF+/btc952fZKaCArJ7a0Yd0wb5u79w58B7v5D4OvcS90qYxJquGcwHzhxB7YvkmjnnnsuM2YEf6ctXLiQr7/+mr322iviqiTusv1T7U9AjzTLejbyc2uTUA8AxpnZWOAzd99gZt8CTgB+3dBGFG4XP0ntrZB9DRo0iJkzZ7J69Wq6dOnCDTfcQGVlJZWVlXTv3p1mzZoxefLkvE8Xyc6n3gHBzLoC3YA9zOzfU15qQwP3OKhnm9sloYafcZuZOWDA7e7+TmO2L5I0mdJGH3rooSJXIknX0B7CYcBAoC1wVsrydcAPGvOB9SShPteY7YmISH7UOyC4exVQZWa93f21ItUkIiIRyPYYwptm9t8EUztbp4rcvbIgVYmISNFle5bRg8DewKnAS0AXgmkjERFJiGwHhIPd/efA+jDU7ky+mfsXEZEEyHbKaFP471oz6w4sByIPT1G4XfzEqbdcLyCrrKzk6aefpkOHDlsvIKs1fvx4Ro4cyapVq3S9gJSsbPcQfhdeH/Bz4CngPeDWXD/MzCrM7DUzezfMM7ow5bUDzOzvZvahmT0aXs0sEhtDhw7l2Wef3W754sWLef7559l3330jqEoke9mG2/3e3T9395fc/UB375BNPHUa/wIGu3s34DRggpm1DV8bB/za3Q8GPgeGNWL7IpHp06cP7dptHwL8k5/8hFtvvVUXjknJy2pAMLOOZjbRzP4cPj/CzOr9hZ0h1bSZu38AWyMqVgLtLfgv5SSCq58BJgPnNq4lkdJRVVVF586dOeqoo6IuRaRB2R5DmATcD1wbPl8IPApMzPSGTKmmta+b2TFAM+AfBNlGa929Ni5yCdA53XaVdhpvceotl8TI2oTJ1FTSr776itGjR3Pbbbdtff7qq6+yxx57FK7oPEtqIigkt7dipJ3OdvejzexNd/92uGyeu1c08L60qaZmVgbMBIa4+ywz2wuYFU4XEUZh/9ndu6ffckBpp/ETp95yOahcmzCZmkr6zjvvcPLJJ7P77rsDsGTJEjp16sTrr7/O3nvvXaiy8yqpiaCQ3N52JO002/8y15vZnoS30TSz44AvsnhfbarprgQXtK03szYE9z241t1nhet9BrQ1s6bhXkIXYGmWtYmUpPLy8m1ubbn//vszZ84cnWUkJSvbAeFKgrOLDjKzV4H2wHezeF/dVNMrCe6d/IC71x4vwN09vOfCd4E/AEOAqoY2rrTT+Elyb+lSSYcN07kREh8NpZ3u6+6fuPsbZtaXIOzOgAXuvqmB96ZLNb0I6APsaWZDw1WHuvs84GrgD2Z2E/Am9RyfEClFmVJJa9W9L7JIqWloD2Eq39wH4VF3Pz/bDdeTavpAhvU/Ao7JdvsiIpJfDZ12mnri9IGFLERERKLV0IDgGR6LiEjCNDRldJSZfUmwp9AifEz43N29TUGrExGRoql3D8Hdd3H3Nu7e2t2bho9rn2swEElRWVlJhw4d6N59+8tnxo8fj5mxevXqCCoTyU5RrxAyswrgboJ7Mm8Gbnb3R+uscydQ6e6tGtqe0k7jJ0695Zp2OnToUIYPH87gwYO3Wa5wO4mLbNNO86W+cDvMrBfwrSLXJJIXCreTuCvYgJBLuF24/i7AbcBVhapJpNgUbidxUrApoxzD7QCGA0+5+7L6/pJSuF28xak3hdslNwAOkttbwcPtGiuHcLtOwB+Bfu5eY2bV2RxDULhd/MSpN4XbJTcADpLbWzHC7Ror23C7bwMHAx+Gewe7m9mHtemnInGkcDuJm0IfVK4Nt5tCEG7XjPThds+4+97uvr+77w/8S4OBxM2gQYPo3bs3CxYsoEuXLkycqDguiZeC7SE0ItwuZ0o7jZ8k96ZwO4m7Qh5Uzincrs57Gzx+ICIi+VXs6xBERKREaUAQERFAA4KIiIQ0IIiICFDkcLt8U7hd/MSpt1zD7SorK3n66afp0KED8+fP3+a18ePHM3LkSFatWqXrEKRkFXUPwcyeNbO1ZvZ0neWTzOxjM5sX/lQUsy6RfBg6dCjPPvvsdsuVdipxUewpo9uA72d4bZS7V4Q/84pYk0heKO1U4q4gA0K6pFMz6+7u04F1hfhMkVKktFOJk4IcQ2go6TSDm83sOmA6MNrdN6ZbSWmn8Ran3pR2mtxEUEhubyWZdlpP0mk/YKS7D0xZtwxYThCH/TvgH+4+pqHPUNpp/MSpN6WdJjcRFJLbW6mmnW6XdJppRXdfFj7caGb3AyMLWJdIUSjtVOKmkANCbdLpAcA4ghvgpGVmZeGNcQw4F2hoeglQuF0cJbm3QYMGMXPmTFavXk2XLl244YYbGDZsWNRliWStIANCuqRTMzsJuAHoCrQysyXAMHd/DphiZu0BA+YBlxeiLpFCUtqpxF2hDipnSjp9McP6JxWiDhERyZ6iK0REBNCAICIiIQ0IIiICaEAQqVdlZSUdOnSge/fuW5f9/Oc/58gjj6SiooJTTjmFTz/9NMIKRfKnJK4QMrP+wK9TFnUFLnL3qfW9T2mn8RN1b7kmmA4dOpThw4czePDgrctGjRrFjTfeCMCdd97JmDFjuOiii/Jap0gUSmJAcPcZQAWAmbUDPgSej7ImEQgC6+qeLtqmTZutj9evX6/QOkmMok8ZZQq+S1nlu8Cf3f1fxa5NJFvXXnst++yzD1OmTGHMmAZTVkRioWBZRvV+qNlNBHEWLYAl7v7LlNdeBH7l7k9neG9quF3P6ybcW4SKi6tjC1ixIeoqCiPq3so75x4st3z5cq655hruv//+7V6bMmUKX3/9Nd/73vdo1apVPkosKdXV1YnsC5LbWzZ99e/fP22WUVQDQqbguzLgbaCTu29qaDsKt4ufqHvL9RgCsE1gXV2ffPIJZ5xxBr/5zW922qC0uEpqbzsSbhfVWUa1wXetCfYUal0APJnNYCASlQ8++GDr46qqKrp27RphNSL5E9WfapmC7wYB10RUk8h20gXWTZs2jQULFtCkSRP2228/7rnnnm0GCZG4KvqAUE/w3UfAPsBL2W5LaafxE7fe0gXWpUsw1YAgSVD0AaGe4DuAzsWuR0REArpSWUREAA0IIiIS0oAgIiKABgQREQlpQBCph9JOZWdS1LOMzOxZ4DjgFXcfmLJ8OPBj4CCgvbuvzmZ7SjuNn6h7U9qpSGbF3kO4Dfh+muWvAt8B/lncckTq16dPH9q1a7fNMqWdSlIVZEDIlGjq7tOBdXXXd/c33X1RIWoRKQSlnUoSFSzcLlOiqZn1A0amThmlvGcR0Ku+KSOlncZb1L0p7TQ3SU0EheT2tiNpp4U8hjCGbxJNr8jXRt39d8DvIEg7TWIqaNSJoIUUdW+Nic1YtGgRLVu2TJsgeeCBB3LGGWdwySWX7LTJmXGV1N52pK9CHkPIlGgqEmtKO5WkKuSfapkSTfNG4XbxE7felHYqO5OCDAj1JJreAHQFWpnZEmCYuz9nZlcAVwF7A2+b2TR3v7QQtYnkQmmnsjMpyIBQT6LpixnWvxO4sxC1iIhIdnSlsoiIABoQREQkpAFBREQADQhS4tKFy61Zs4YBAwZwyCGHMGDAAD7//PMIKxRJjmKH2+0HPEkwEO0K3OXu94Sv9QQmEVzZPA0Y4Q1cRq1wu/iZdFrLnNZPFy43duxYTj75ZEaPHs3YsWMZO3Ys48aNy3epIjudYu8hLAN6u3sFwZlHo82sU/ja3cAPgEPCn9OKXJuUoHThclVVVQwZMgSAIUOGMHXq1AgqE0megg0I6QLugEPdfWO4SvPazzezMqCNu88K9woeAM4tVG0SbytWrKCsrAyAvffemxUrVkRckUgyFGzKyN1nm9lTwE0E00APuft8M9sHeAY4GBjl7p+aWS9gScrblwCdC1WbJIeZKX5aJE8KfQxhu4A7d18MHBlOFU01sz/lssE6aadcV16T34pLQMcWwXGEJKqurmbmzJk5vWf58uWsX79+6/vatGnD448/zp577slnn31G69atc95mvjWmrzhIal+Q3N52pK9CDwi1AXe7EgTcra99IdwzmA+cSHCDnC4p7+sCLE23QaWdxtuk09KnhtanbtrohRdeyAcffMD555/P2LFjueiiiyJPrVRyZvwktbdSTTuFbwLupgDjzKyLmbUAMLNvAScAC9x9GfClmR1nwf7/YKCqwLVJDAwaNIjevXuzYMECunTpwsSJExk9ejQvvPAChxxyCH/5y18YPXp01GWKJELB/gxNF3AHdANuMzMHDLjd3d8J3/JffHPa6Z/Dn3op7TR+ct2VTRcuBzB9+vQ8VCMiqQp5UDlTwN1zGdafA3RP95qIiBSerlQWERFAA4KIiIQ0IIiICKABQUREQhoQpKQp7VSkeIp29ZOZVRAE2LUBNgM3u/uj4WvDgR8DBwHt3X11NttU2mn8KO1UpHQVcw/hX8Bgd+9GkGQ6wczahq+9CnwH+GcR65EYUNqpSPEUZEDIkHTazN0/gCC2AlgJtA+fv+nuiwpRiySP0k5FCqMgU0aZkk5rXzezY4BmwD9y3bbC7eItH+F2NTU122xj8+bNkYeUKSgtfpLaW6mG222XdApb733wIDDE3bfkulGF28VbPsLtOnfuzGGHHUZZWRnLli2jU6dOkYeUKSgtfpLaW6mG29UmnbYmSDrFzNoQ3AvhWnefVcDPlgQ7++yzmTx5MgCTJ0/mnHPOibgikWQo5IBQN+m0GcH9lB9w95zugSA7L6WdihRPQeYlMiSdXgT0AfY0s6HhqkPdfZ6ZXQFcBewNvG1m09z90oY+R2mn8aO0U5HSVaiDypmSTh/IsP6dwJ2FqEVERLKjK5VFRATQgCAiIiENCCIiAmhAEBGRkAYEEREBNCCIiEhIA4KIiAAaEEREJGTuHnUNjWZm64AFUddRAHsBWd0kKIaS2pv6ip+k9pZNX/u5e/u6C+MeqbnA3XtFXUS+mdmcJPYFye1NfcVPUnvbkb40ZSQiIoAGBBERCcV9QPhd1AUUSFL7guT2pr7iJ6m9NbqvWB9UFhGR/In7HoKIiOSJBgQREQFiOiCY2WlmtsDMPjSzRN0/0cwWmdk7ZjbPzOZEXU9jmdl9ZrbSzOanLGtnZi+Y2Qfhv9+KssbGytDb9Wa2NPze5pnZGVHW2Bhmto+ZzTCz98zsXTMbES6P9fdWT1+x/s7MbDcze93M3gr7uiFcfoCZ/T38/fhoePvi7LYZt2MI4S05FwIDgCXAbGCQu78XaWF5YmaLgF7uHusLZsysD1BNcA/t7uGyW4E17j42HMi/5e5XR1lnY2To7Xqg2t1vj7K2HWFmZUCZu79hZq2BucC5wFBi/L3V09cFxPg7MzMDWrp7tZntCrwCjACuBJ5w9z+Y2T3AW+5+dzbbjOMewjHAh+7+kbt/DfwBOCfimqQOd/8rsKbO4nOAyeHjyQT/UcZOht5iz92Xufsb4eN1wPtAZ2L+vdXTV6x5oDp8umv448BJwJ/C5Tl9X3EcEDoDi1OeLyEBX24KB543s7lm9sOoi8mzju6+LHy8HOgYZTEFMNzM3g6nlGI1rVKXme0PfBv4Own63ur0BTH/zsxsFzObB6wEXgD+Aax195pwlZx+P8ZxQEi6E9y9B3A68N/h9ETieDBXGa/5yvrdDRwEVADLgPGRVrMDzKwV8DjwY3f/MvW1OH9vafqK/Xfm7pvdvQLoQjB70nVHthfHAWEpsE/K8y7hskRw96XhvyuBJwm+5KRYEc7n1s7rroy4nrxx9xXhf5xbgHuJ6fcWzkU/Dkxx9yfCxbH/3tL1lZTvDMDd1wIzgN5AWzOrzanL6fdjHAeE2cAh4ZH0ZsBFwFMR15QXZtYyPOiFmbUETgHm1/+uWHkKGBI+HgJURVhLXtX+wgydRwy/t/Ag5UTgfXf/VcpLsf7eMvUV9+/MzNqbWdvwcQuCE23eJxgYvhuultP3FbuzjADC08MmALsA97n7zdFWlB9mdiDBXgEESbQPx7U3M3sE6EcQxbsC+AUwFfgjsC/wT+ACd4/dwdkMvfUjmHpwYBFwWcq8eyyY2QnAy8A7wJZw8c8I5ttj+73V09cgYvydmdmRBAeNdyH44/6P7j4m/D3yB6Ad8CZwsbtvzGqbcRwQREQk/+I4ZSQiIgWgAUFERAANCCIiEtKAICIigAYEEREJNW14FZGdi5ltJjhFsda57r4oonJEikannYrUYWbV7t6qiJ/XNCV7RiQymjISyZGZlZnZX8MM/flmdmK4/DQzeyPMp58eLmtnZlPDALVZ4cVEtVn8D5rZq8CD4VWnj5vZ7PDn+AhblJ2UpoxEttciTJAE+Njdz6vz+n8Az7n7zeH9OXY3s/YEeTh93P1jM2sXrnsD8Ka7n2tmJwEPEFwdC3AEQZjhBjN7GPi1u79iZvsCzwGHF6xDkTQ0IIhsb0OYIJnJbOC+MDBtqrvPM7N+wF/d/WOAlGiHE4Dzw2UvmtmeZtYmfO0pd98QPv4OcEQQuwNAGzNrlZJ3L1JwGhBEcuTufw1jyc8EJpnZr4DPG7Gp9SmPmwDHuftX+ahRpDF0DEEkR2a2H7DC3e8Ffg/0AGYBfczsgHCd2imjl4H/DJf1A1bXvcdA6HngRymfUVGg8kUy0h6CSO76AaPMbBPBvZUHu/uq8A53T5hZE4J7BgwArieYXnob+BffxEjXdQXw23C9psBfgcsL2oVIHTrtVEREAE0ZiYhISAOCiIgAGhBERCSkAUFERAANCCIiEtKAICIigAYEEREJ/X+FXiDTT3HwZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model \n",
    "pre_model = None\n",
    "\n",
    "data_train = xgb.DMatrix(X_train, y_train)  # 使用XGBoost的原生版本需要对数据进行转化\n",
    "data_val = xgb.DMatrix(X_val, y_val)\n",
    "param = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',  # multi-classification algorithm\n",
    "    #'objective': 'binary:logistic', # binary-classification algorithm\n",
    "    #'num_class': 7,               # set number of classes needed to classify, if using the softmax function, it needed to be set\n",
    "    'gamma': 0.2,                  # Minimum loss reduction required to make a further partition on a leaf node of the tree.Generally setting 0.1,0.2\n",
    "    'max_depth': 3,               # Maximum depth of a tree. Increasing value will make more complex and may likely to overfit\n",
    "    'lambda': 0.4,                 # L2 regularization term on weights. Can avoid the model overfitting.\n",
    "    'alpha':12,                    # L1 regularization term on weights. Increasing this value will make model more conservative.\n",
    "    'subsample': 0.2,              # ratio of the training instances.  Randomly sample of the training data by using this ratio and prior to growing trees. It used to prevent overfitting.\n",
    "    'colsample_bytree': 0.5,       # the subsample ratio of columns when constructing each tree\n",
    "    'min_child_weight': 1,         # Minimum sum of instance weight (hessian) needed in a child\n",
    "    \"max_delta_step\":0,            # Maximum delta step we allow each leaf output to be\n",
    "    'eta': 0.2,                    # it seems like learning rate.\n",
    "    #\"scale_pos_weight\":1,         #benifit converge quickly in unbalance situation\n",
    "    'silent': 0,                   # if setting on 1, it would no have executed information output, the better way is set to 0\n",
    "    'nthread': 4,                  # Number of parallel threads used to run XGBoost\n",
    "    #\"min_child_weight\":1,          #minimum subtree\n",
    "    \"eval_metric\": [\"auc\"] #can combine to use the function of evaluate the data.\n",
    "}\n",
    "\n",
    "watchlist = [(data_train, 'train'),(data_val, 'val')]\n",
    "n_round = 50\n",
    "evals_result={}\n",
    "booster = xgb.train(param, data_train,num_boost_round = n_round,evals = watchlist,xgb_model = pre_model,evals_result=evals_result)\n",
    "\n",
    "# get importance\n",
    "plot_importance(booster,\n",
    "                 height=0.5,\n",
    "                 max_num_features=15)\n",
    "\n",
    "# save the model\n",
    "#booster.save_model('./model/xgb.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
